{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87032f06",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Simple-Linear-Regression\" data-toc-modified-id=\"Simple-Linear-Regression-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Simple Linear Regression</a></span></li><li><span><a href=\"#Multiple-Regression\" data-toc-modified-id=\"Multiple-Regression-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Multiple Regression</a></span></li><li><span><a href=\"#Nonlinear-Regression\" data-toc-modified-id=\"Nonlinear-Regression-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Nonlinear Regression</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cecaa47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from pandas.plotting import scatter_matrix\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "%matplotlib inline\n",
    "from datetime import datetime\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83744488",
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0db2ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "vti_df = pd.read_csv('C:/Users/624013/Documents/TEDS/VTI.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d496f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "vti_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2c447e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vti_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe23d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(vti_df))  #<- a Pandas DataFrame\n",
    "print(len(vti_df))   #<- returns the number of rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a8c692",
   "metadata": {},
   "source": [
    "# Simple Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42162bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Simple linear regression\n",
    "\n",
    "# Subset the two variables for simple linear regression.\n",
    "df_subset = vti_df[['Adj Close', 'Date']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ceccffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Summary statistics: dependent and independent variables \n",
    "\n",
    "# Describe the `change` summary statistics.\n",
    "print(df_subset['Adj Close'].describe())\n",
    "# Describe the `'calories'` summary statistics.\n",
    "print(df_subset['Date'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e82e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Summary statistics: covariance in Python\n",
    "\n",
    "print(df_subset.cov())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0f00d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Summary statistics: correlation (scaled cov) \n",
    "\n",
    "df_subset.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a156e5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDA: scatter plot  \n",
    "\n",
    "plt.scatter(df_subset['Adj Close'],\n",
    "            df_subset['Date'])\n",
    "plt.title('Adj Close' + \" vs Date\")\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel(\"Adj Close\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e164a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#EDA: histogram - `Adj Close`  \n",
    "\n",
    "plt.hist(df_subset['Adj Close'], bins = 10)\n",
    "plt.xlabel('Adj Close')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90b5291",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df_subset['Volume'], bins = 10)\n",
    "plt.xlabel('Volume')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f862b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data cleaning: NAs \n",
    "\n",
    "# Check how many values are null in the `change` column.\n",
    "print(df_subset['Adj Close'].isnull().sum())\n",
    "# Check how many values are null in the `'calories'` column.\n",
    "print(df_subset['Volume'].isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347424ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data cleaning: NAs \n",
    "\n",
    "print(df_subset[df_subset['Adj Close'].isnull()])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4b99c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data cleaning: use fillna()\n",
    "\n",
    "# Set the dataframe equal to the imputed dataset.\n",
    "df_subset = df_subset.fillna(df_subset.mean())\n",
    "\n",
    "# Check how many values are null in the `change` column.\n",
    "print(df_subset['Adj Close'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac45b719",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data cleaning: testing for near zero variance  \n",
    "\n",
    "# Using sklearn, look for low variance within the columns.\n",
    "# First, we'll instantiate the function.\n",
    "selector = VarianceThreshold()\n",
    "\n",
    "# Next, name the cleaned dataset df_subset_clean.\n",
    "df_subset_clean = selector.fit_transform(df_subset)\n",
    "\n",
    "# Let's see if the dimensions changed.\n",
    "print(df_subset_clean.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c809f16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Implement linear regression \n",
    "\n",
    "# Two variables for single regression.\n",
    "X = pd.DataFrame(df_subset_clean[:,1]) # independent variable\n",
    "\n",
    "# Make sure to add a constant term so that we have a column for the intercept.\n",
    "X = sm.add_constant(X)\n",
    "y = pd.DataFrame(df_subset_clean[:,0])  # dependent variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53219cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the seed \n",
    "\n",
    "# Set the random seed equal to 1.\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ef8035",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement: build a linear model \n",
    "\n",
    "# Build the model, note the difference in argument order.\n",
    "model = sm.OLS(y, X).fit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649e905a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Implement: build a linear model\n",
    "\n",
    "# Inspect the output of the `sm.OLS` function.\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db6bf90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Implement: plot the fit \n",
    "\n",
    "# Code to plot using matlplotlib.pyplot and statsmodel abline_plot.\n",
    "fig = sm.graphics.abline_plot(model_results = model)\n",
    "ax = fig.axes[0]\n",
    "plt.scatter(df_subset['Volume'],\n",
    "            df_subset['Adj Close'])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f7aa92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate: residual standard error  \n",
    "\n",
    "# Residual standard error\n",
    "print(np.sqrt(model.scale))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2324edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting the residuals \n",
    "\n",
    "fitted = model.fittedvalues\n",
    "print(fitted.head())\n",
    "residuals = model.resid\n",
    "print(residuals.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f782003a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check for linearity\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "plot_lm_1 = plt.figure(1)\n",
    "plot_lm_1.set_figheight(8)\n",
    "plot_lm_1.set_figwidth(12)\n",
    "\n",
    "plot_lm_1.axes[0] = sns.residplot(fitted, 'Adj Close', \n",
    "                    data=df_subset, \n",
    "                    lowess = True, \n",
    "                    scatter_kws = {'alpha': 0.5}, \n",
    "                    line_kws = {'color': 'red', 'lw': 1, 'alpha': 0.8})\n",
    "\n",
    "plot_lm_1.axes[0].set_title('Residuals vs Fitted')\n",
    "plot_lm_1.axes[0].set_xlabel('Fitted values')\n",
    "plot_lm_1.axes[0].set_ylabel('Residuals')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6f1f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check for normal distribution \n",
    "\n",
    "from statsmodels.graphics.gofplots import ProbPlot\n",
    "\n",
    "model_norm_residuals = model.get_influence().resid_studentized_internal\n",
    "QQ = ProbPlot(model_norm_residuals)\n",
    "plot_lm_2 = QQ.qqplot(line= '45', alpha = 0.5, color = '#4C72B0', lw = 1)\n",
    "\n",
    "plot_lm_2.set_figheight(8)\n",
    "plot_lm_2.set_figwidth(12)\n",
    "\n",
    "plot_lm_2.axes[0].set_title('Normal Q-Q')\n",
    "plot_lm_2.axes[0].set_xlabel('Theoretical Quantiles')\n",
    "plot_lm_2.axes[0].set_ylabel('Standardized Residuals')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4364d084",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for equal variance \n",
    "\n",
    "model_norm_residuals_abs_sqrt = np.sqrt(np.abs(model_norm_residuals))\n",
    "plot_lm_3 = plt.figure(3)\n",
    "plot_lm_3.set_figheight(8)\n",
    "plot_lm_3.set_figwidth(12)\n",
    "\n",
    "plt.scatter(fitted, model_norm_residuals_abs_sqrt, alpha = 0.5)\n",
    "sns.regplot(fitted, model_norm_residuals_abs_sqrt,\n",
    "            scatter = False, \n",
    "            ci = False, \n",
    "            lowess = True,\n",
    "            line_kws = {'color': 'red', 'lw': 1, 'alpha': 0.8})\n",
    "\n",
    "plot_lm_3.axes[0].set_title('Scale-Location')\n",
    "plot_lm_3.axes[0].set_xlabel('Fitted values')\n",
    "plot_lm_3.axes[0].set_ylabel('sqrt(|Standardized Residuals|)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47330c8e",
   "metadata": {},
   "source": [
    "# Multiple Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4efde2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Slide 13/31: Subset data  ####\n",
    "all_features = ['Open', 'High', 'Low', 'Volume']\n",
    "all_features.append(\"Adj Close\")\n",
    "\n",
    "df_subset = vti_df[all_features]\n",
    "df_subset.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7072ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 17/31: Summary statistics: describe the dataset  ####\n",
    "\n",
    "# Let's look at the summary statistics.\n",
    "print(df_subset.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1e9729",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Summary statistics: covariance\n",
    "print(df_subset.cov())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eadcbf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Summary statistics: correlation\n",
    "print(df_subset.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f73e535",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Histogram of the target variable\n",
    "plt.hist(df_subset[\"Adj Close\"],  bins = 10)\n",
    "plt.xlabel(\"Adj Close\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2be999a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make scatter plot.\n",
    "scatter_m = scatter_matrix(df_subset)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea7611e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check how many values are null in the dataset.\n",
    "print(df_subset.isnull().sum())\n",
    "# Drop NA's from the data\n",
    "df_subset = df_subset.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc13b876",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Slide 27/31: Data cleaning: near-zero variance  ####\n",
    "\n",
    "# Using sklearn, let's look for low variance within the columns.\n",
    "# First, instantiate the function.\n",
    "selector = VarianceThreshold()\n",
    "# Then, name the cleaned dataset df_subset_clean.\n",
    "df_subset_clean = selector.fit_transform(df_subset)\n",
    "# Let's see if the dimensions changed.\n",
    "print(df_subset_clean.shape)\n",
    "print(df_subset_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca8e22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Data cleaning: near-zero variance  ####\n",
    "\n",
    "# Let's convert the numpy array back to a DataFrame for convenience.\n",
    "df_subset_clean = pd.DataFrame(df_subset_clean, columns = all_features)\n",
    "df_subset_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48143936",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set X to ['Open', 'High', 'Low', 'Volume'].  \n",
    "X = df_subset_clean[['Open', 'High', 'Low', 'Volume']]\n",
    "# Add a constant.\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Set y to `Adj Close`.\n",
    "y = df_subset_clean[[\"Adj Close\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e156d3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Apply regression to the dataset  ####\n",
    "\n",
    "# Set the seed.\n",
    "np.random.seed(1)\n",
    "\n",
    "# Create the train and test sets.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)\n",
    "\n",
    "# Check to see if the datasets split correctly.\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f792ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "####  Multiple linear regression on a dataset  ####\n",
    "\n",
    "# Build a linear model on training data.\n",
    "model_m = sm.OLS(y_train, X_train).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef8b167",
   "metadata": {},
   "outputs": [],
   "source": [
    "####  Assumptions: plot  ####\n",
    "\n",
    "fitted_m = model_m.fittedvalues\n",
    "print(fitted_m.head())\n",
    "residuals_m = model_m.resid\n",
    "print(residuals_m.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f3b462",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Assumptions: plot (cont’d.)  ####\n",
    "\n",
    "# Get the normalized residuals.\n",
    "model_m_norm_residuals = model_m.get_influence().resid_studentized_internal\n",
    "# Get the absolute squared normalized residuals.\n",
    "model_m_norm_residuals_abs_sqrt = np.sqrt(np.abs(model_m_norm_residuals))\n",
    "# Get the absolute residuals. \n",
    "model_m_abs_resid = np.abs(residuals_m)\n",
    "# Combine X_train and y_train into one dataframe for plotting.\n",
    "frames = [X_train,y_train]\n",
    "training = pd.concat(frames, axis = 1) # axis = 1 allows us to combine by columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c979b69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "####  Assumption: residuals vs. fitted   ####\n",
    "\n",
    "import seaborn as sns\n",
    "# Let's look at assumption 1.\n",
    "plot_lm_1 = plt.figure(1)\n",
    "plot_lm_1.set_figheight(8)\n",
    "plot_lm_1.set_figwidth(12)\n",
    "plot_lm_1.axes[0] = sns.residplot(fitted_m, \"Adj Close\", data = training, \n",
    "                          lowess = True, \n",
    "                          scatter_kws = {'alpha': 0.5}, \n",
    "                          line_kws = {'color': 'red', 'lw': 1, 'alpha': 0.8})\n",
    "plot_lm_1.axes[0].set_title('Residuals vs Fitted')\n",
    "plot_lm_1.axes[0].set_xlabel('Fitted values')\n",
    "plot_lm_1.axes[0].set_ylabel('Residuals')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2adc1ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Assumption: normally distributed residuals  ####\n",
    "\n",
    "from statsmodels.graphics.gofplots import ProbPlot\n",
    "\n",
    "QQ = ProbPlot(model_m_norm_residuals)\n",
    "plot_lm_2 = QQ.qqplot(line = '45', alpha = 0.5, color = '#4C72B0', lw = 1)\n",
    "\n",
    "plot_lm_2.set_figheight(8)\n",
    "plot_lm_2.set_figwidth(12)\n",
    "\n",
    "plot_lm_2.axes[0].set_title('Normal Q-Q')\n",
    "plot_lm_2.axes[0].set_xlabel('Theoretical Quantiles')\n",
    "plot_lm_2.axes[0].set_ylabel('Standardized Residuals');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df92f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Slide 26/30: Assumption: equal residual variance  ####\n",
    "\n",
    "plot_lm_3 = plt.figure(3)\n",
    "plot_lm_3.set_figheight(8)\n",
    "plot_lm_3.set_figwidth(12)\n",
    "\n",
    "plt.scatter(fitted_m, model_m_norm_residuals_abs_sqrt, alpha = 0.5)\n",
    "sns.regplot(fitted_m, model_m_norm_residuals_abs_sqrt, \n",
    "            scatter = False, \n",
    "            ci = False, \n",
    "            lowess = True,\n",
    "            line_kws = {'color': 'red', 'lw': 1, 'alpha': 0.8})\n",
    "\n",
    "plot_lm_3.axes[0].set_title('Scale-Location')\n",
    "plot_lm_3.axes[0].set_xlabel('Fitted values')\n",
    "plot_lm_3.axes[0].set_ylabel('$\\sqrt{|Standardized Residuals|}$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8da9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "####  Influential cases: residuals vs. leverage  ####\n",
    "\n",
    "# Identify the influential points ('\\n' syntax creates a new line in the output).\n",
    "test_m = model_m.outlier_test()\n",
    "print(\"Bad data points (bonf(p) < 0.05):\\n\", test_m[test_m['bonf(p)'] < 0.05])\n",
    "# Save the final outliers.\n",
    "test_final_m = test_m[test_m['bonf(p)'] < 0.05]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f57a884",
   "metadata": {},
   "outputs": [],
   "source": [
    "####  Removing outliers from regression dataset  ####\n",
    "\n",
    "test_final_m = test_m[test_m['bonf(p)'] < 0.05]\n",
    "# Make sure that you drop outliers from both X and y train sets.\n",
    "X_train_no_outliers = X_train.drop(test_final_m.index)\n",
    "y_train_no_outliers = y_train.drop(test_final_m.index)\n",
    "# Look at the shape of the new DataFrame to check that the rows have actually been dropped.\n",
    "print(X_train_no_outliers.shape)\n",
    "print(y_train_no_outliers.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04387f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Rerun multiple regression model  ####\n",
    "\n",
    "# Build a linear model on training data.\n",
    "model_m_no_outliers = sm.OLS(y_train_no_outliers, X_train_no_outliers).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8040f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Testing the model  ####\n",
    "\n",
    "vif = pd.DataFrame()\n",
    "vif[\"VIF Factor\"] = [variance_inflation_factor(X_train_no_outliers.values, i) for i in range(X_train_no_outliers.shape[1])]\n",
    "vif[\"features\"] = X_train_no_outliers.columns\n",
    "print(vif)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d5d88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Testing the model (cont'd)  ####\n",
    "\n",
    "if vif[vif['VIF Factor'] > 10].features.shape[0] > 0:\n",
    "    print(\"Multicollinearity exists in our model\")\n",
    "else:\n",
    "    print(\"No multicollinearity exists in our model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e521dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Predict: `Adj Close` in test data  ####\n",
    "\n",
    "# Predict values of `Calories` using the test data.\n",
    "prediction = model_m_no_outliers.predict(X_test)\n",
    "print(prediction.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69dd985d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Slide 18/24: Predict: residuals of model  ####\n",
    "\n",
    "actual = y_test[\"Adj Close\"]\n",
    "prediction = model_m_no_outliers.predict(X_test)\n",
    "residuals = y_test[\"Adj Close\"] - prediction\n",
    "\n",
    "\n",
    "results =  pd.concat([actual.rename('actual'),\n",
    "                              prediction.rename('predicted'),\n",
    "                              residuals.rename('residuals')], axis = 1)\n",
    "print(results.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41373728",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### redict: mean squared error  ####\n",
    "\n",
    "def rmse(predictions,actual):\n",
    "    return np.sqrt(((prediction-actual) ** 2).mean())\n",
    "\n",
    "print(rmse(prediction,actual))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da684b43",
   "metadata": {},
   "source": [
    "# Nonlinear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebbe8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Slide 10: Transforming target to log \n",
    "vti_df['Adj Close_log'] = np.log(vti_df['Adj Close'])\n",
    "vti_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07269a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the log-lin model  \n",
    "\n",
    "vti_df = sm.add_constant(vti_df)\n",
    "model_lin = sm.OLS(vti_df['Adj Close_log'], vti_df.loc[:,['const','Volume']]).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f8729b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_lin = model_lin.predict(vti_df.loc[:,['const','Volume']])\n",
    "prediction_lin[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b89ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = np.exp(prediction_lin)\n",
    "prediction[1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61bf8b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Slide 14: Evaluating the log-lin model: chart  ####\n",
    "\n",
    "plt.scatter(vti_df['Volume'],vti_df['Adj Close'])\n",
    "plt.plot(vti_df['Volume'], prediction, 'red')\n",
    "plt.title(\"Index price over time\")\n",
    "plt.xlabel(\"Days\")\n",
    "plt.ylabel(\"Index price\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f9a0f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

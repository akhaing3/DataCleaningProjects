{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87fb0146",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#VTI-Analysis\" data-toc-modified-id=\"VTI-Analysis-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>VTI Analysis</a></span></li><li><span><a href=\"#Data\" data-toc-modified-id=\"Data-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Data</a></span><ul class=\"toc-item\"><li><span><a href=\"#Import-Dataset\" data-toc-modified-id=\"Import-Dataset-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Import Dataset</a></span></li><li><span><a href=\"#Inspect-Dataset\" data-toc-modified-id=\"Inspect-Dataset-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Inspect Dataset</a></span></li><li><span><a href=\"#Changes-based-on-Adj-Close-Prices\" data-toc-modified-id=\"Changes-based-on-Adj-Close-Prices-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Changes based on Adj Close Prices</a></span></li></ul></li><li><span><a href=\"#Simple-Linear-Regression\" data-toc-modified-id=\"Simple-Linear-Regression-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Simple Linear Regression</a></span><ul class=\"toc-item\"><li><span><a href=\"#Explore-the-data\" data-toc-modified-id=\"Explore-the-data-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Explore the data</a></span><ul class=\"toc-item\"><li><span><a href=\"#Create-a-Statistical-Summary\" data-toc-modified-id=\"Create-a-Statistical-Summary-3.1.1\"><span class=\"toc-item-num\">3.1.1&nbsp;&nbsp;</span>Create a Statistical Summary</a></span></li><li><span><a href=\"#Measure-thecorrelation\" data-toc-modified-id=\"Measure-thecorrelation-3.1.2\"><span class=\"toc-item-num\">3.1.2&nbsp;&nbsp;</span>Measure thecorrelation</a></span></li><li><span><a href=\"#Checking-for-Outliers-and-Skewness\" data-toc-modified-id=\"Checking-for-Outliers-and-Skewness-3.1.3\"><span class=\"toc-item-num\">3.1.3&nbsp;&nbsp;</span>Checking for Outliers and Skewness</a></span></li><li><span><a href=\"#testing-for-near-zero-variance\" data-toc-modified-id=\"testing-for-near-zero-variance-3.1.4\"><span class=\"toc-item-num\">3.1.4&nbsp;&nbsp;</span>testing for near zero variance</a></span></li><li><span><a href=\"#OLS\" data-toc-modified-id=\"OLS-3.1.5\"><span class=\"toc-item-num\">3.1.5&nbsp;&nbsp;</span>OLS</a></span><ul class=\"toc-item\"><li><span><a href=\"#Split-the-Data\" data-toc-modified-id=\"Split-the-Data-3.1.5.1\"><span class=\"toc-item-num\">3.1.5.1&nbsp;&nbsp;</span>Split the Data</a></span></li><li><span><a href=\"#Explore\" data-toc-modified-id=\"Explore-3.1.5.2\"><span class=\"toc-item-num\">3.1.5.2&nbsp;&nbsp;</span>Explore</a></span></li></ul></li></ul></li><li><span><a href=\"#Assumptions-of-the-Model\" data-toc-modified-id=\"Assumptions-of-the-Model-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Assumptions of the Model</a></span><ul class=\"toc-item\"><li><span><a href=\"#1st-Assumption:-Linear-Relationship\" data-toc-modified-id=\"1st-Assumption:-Linear-Relationship-3.2.1\"><span class=\"toc-item-num\">3.2.1&nbsp;&nbsp;</span>1st Assumption: Linear Relationship</a></span></li><li><span><a href=\"#Assumption-2:-Independent-Residuals\" data-toc-modified-id=\"Assumption-2:-Independent-Residuals-3.2.2\"><span class=\"toc-item-num\">3.2.2&nbsp;&nbsp;</span>Assumption 2: Independent Residuals</a></span></li><li><span><a href=\"#Assumption-3:-Normal-Distribution\" data-toc-modified-id=\"Assumption-3:-Normal-Distribution-3.2.3\"><span class=\"toc-item-num\">3.2.3&nbsp;&nbsp;</span>Assumption 3: Normal Distribution</a></span></li><li><span><a href=\"#Assumption-4:-Equal-Variance\" data-toc-modified-id=\"Assumption-4:-Equal-Variance-3.2.4\"><span class=\"toc-item-num\">3.2.4&nbsp;&nbsp;</span>Assumption 4: Equal Variance</a></span></li></ul></li><li><span><a href=\"#Assumptions-Violated\" data-toc-modified-id=\"Assumptions-Violated-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Assumptions Violated</a></span></li></ul></li><li><span><a href=\"#Multiple-Regression\" data-toc-modified-id=\"Multiple-Regression-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Multiple Regression</a></span><ul class=\"toc-item\"><li><span><a href=\"#OLS\" data-toc-modified-id=\"OLS-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>OLS</a></span><ul class=\"toc-item\"><li><span><a href=\"#1st-Assumption:-Linear-Relationship\" data-toc-modified-id=\"1st-Assumption:-Linear-Relationship-4.1.1\"><span class=\"toc-item-num\">4.1.1&nbsp;&nbsp;</span>1st Assumption: Linear Relationship</a></span></li><li><span><a href=\"#Assumption-3:-Normal-Distribution\" data-toc-modified-id=\"Assumption-3:-Normal-Distribution-4.1.2\"><span class=\"toc-item-num\">4.1.2&nbsp;&nbsp;</span>Assumption 3: Normal Distribution</a></span></li><li><span><a href=\"#Assumption-4:-Equal-Variance\" data-toc-modified-id=\"Assumption-4:-Equal-Variance-4.1.3\"><span class=\"toc-item-num\">4.1.3&nbsp;&nbsp;</span>Assumption 4: Equal Variance</a></span></li></ul></li></ul></li><li><span><a href=\"#Nonlinear-Regression\" data-toc-modified-id=\"Nonlinear-Regression-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Nonlinear Regression</a></span><ul class=\"toc-item\"><li><span><a href=\"#Log-log\" data-toc-modified-id=\"Log-log-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Log-log</a></span></li><li><span><a href=\"#Log-Lin\" data-toc-modified-id=\"Log-Lin-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>Log-Lin</a></span></li><li><span><a href=\"#Polynomial\" data-toc-modified-id=\"Polynomial-5.3\"><span class=\"toc-item-num\">5.3&nbsp;&nbsp;</span>Polynomial</a></span></li></ul></li><li><span><a href=\"#Classification\" data-toc-modified-id=\"Classification-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Classification</a></span><ul class=\"toc-item\"><li><span><a href=\"#Data-Prep-for-Classification\" data-toc-modified-id=\"Data-Prep-for-Classification-6.1\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;</span>Data Prep for Classification</a></span><ul class=\"toc-item\"><li><span><a href=\"#Identify-the-the-unique-classes\" data-toc-modified-id=\"Identify-the-the-unique-classes-6.1.1\"><span class=\"toc-item-num\">6.1.1&nbsp;&nbsp;</span>Identify the the unique classes</a></span></li></ul></li><li><span><a href=\"#KNN\" data-toc-modified-id=\"KNN-6.2\"><span class=\"toc-item-num\">6.2&nbsp;&nbsp;</span>KNN</a></span><ul class=\"toc-item\"><li><span><a href=\"#Scale\" data-toc-modified-id=\"Scale-6.2.1\"><span class=\"toc-item-num\">6.2.1&nbsp;&nbsp;</span>Scale</a></span></li><li><span><a href=\"#Create-kNN-classifier\" data-toc-modified-id=\"Create-kNN-classifier-6.2.2\"><span class=\"toc-item-num\">6.2.2&nbsp;&nbsp;</span>Create kNN classifier</a></span></li><li><span><a href=\"#Confusion-matrix\" data-toc-modified-id=\"Confusion-matrix-6.2.3\"><span class=\"toc-item-num\">6.2.3&nbsp;&nbsp;</span>Confusion matrix</a></span></li><li><span><a href=\"#AUC-&amp;-ROC\" data-toc-modified-id=\"AUC-&amp;-ROC-6.2.4\"><span class=\"toc-item-num\">6.2.4&nbsp;&nbsp;</span>AUC &amp; ROC</a></span></li><li><span><a href=\"#Grid-Search-to-find-optimal-hyperparameters\" data-toc-modified-id=\"Grid-Search-to-find-optimal-hyperparameters-6.2.5\"><span class=\"toc-item-num\">6.2.5&nbsp;&nbsp;</span>Grid Search to find optimal hyperparameters</a></span></li></ul></li><li><span><a href=\"#Logistic-Regression\" data-toc-modified-id=\"Logistic-Regression-6.3\"><span class=\"toc-item-num\">6.3&nbsp;&nbsp;</span>Logistic Regression</a></span><ul class=\"toc-item\"><li><span><a href=\"#Convert-Target-to-Binary\" data-toc-modified-id=\"Convert-Target-to-Binary-6.3.1\"><span class=\"toc-item-num\">6.3.1&nbsp;&nbsp;</span>Convert Target to Binary</a></span></li><li><span><a href=\"#Check-for-NAs\" data-toc-modified-id=\"Check-for-NAs-6.3.2\"><span class=\"toc-item-num\">6.3.2&nbsp;&nbsp;</span>Check for NAs</a></span></li><li><span><a href=\"#Split-data-into-train-and-test-sets\" data-toc-modified-id=\"Split-data-into-train-and-test-sets-6.3.3\"><span class=\"toc-item-num\">6.3.3&nbsp;&nbsp;</span>Split data into train and test sets</a></span></li><li><span><a href=\"#Scale-the-features.\" data-toc-modified-id=\"Scale-the-features.-6.3.4\"><span class=\"toc-item-num\">6.3.4&nbsp;&nbsp;</span>Scale the features.</a></span></li><li><span><a href=\"#Logistic-regression:-build\" data-toc-modified-id=\"Logistic-regression:-build-6.3.5\"><span class=\"toc-item-num\">6.3.5&nbsp;&nbsp;</span>Logistic regression: build</a></span></li><li><span><a href=\"#Confusion-matrix-and-accuracy\" data-toc-modified-id=\"Confusion-matrix-and-accuracy-6.3.6\"><span class=\"toc-item-num\">6.3.6&nbsp;&nbsp;</span>Confusion matrix and accuracy</a></span></li><li><span><a href=\"#Computing-FPR,-TPR,-and-threshold\" data-toc-modified-id=\"Computing-FPR,-TPR,-and-threshold-6.3.7\"><span class=\"toc-item-num\">6.3.7&nbsp;&nbsp;</span>Computing FPR, TPR, and threshold</a></span></li><li><span><a href=\"#Accuracy-on-train-vs.-accuracy-on-test\" data-toc-modified-id=\"Accuracy-on-train-vs.-accuracy-on-test-6.3.8\"><span class=\"toc-item-num\">6.3.8&nbsp;&nbsp;</span>Accuracy on train vs. accuracy on test</a></span></li><li><span><a href=\"#Grid-Search-to-find-optimal-hyperparameters\" data-toc-modified-id=\"Grid-Search-to-find-optimal-hyperparameters-6.3.9\"><span class=\"toc-item-num\">6.3.9&nbsp;&nbsp;</span>Grid Search to find optimal hyperparameters</a></span></li><li><span><a href=\"#Predict-using-the-best-model-parameters\" data-toc-modified-id=\"Predict-using-the-best-model-parameters-6.3.10\"><span class=\"toc-item-num\">6.3.10&nbsp;&nbsp;</span>Predict using the best model parameters</a></span></li></ul></li><li><span><a href=\"#Decision-Tree\" data-toc-modified-id=\"Decision-Tree-6.4\"><span class=\"toc-item-num\">6.4&nbsp;&nbsp;</span>Decision Tree</a></span></li><li><span><a href=\"#Random-Forest\" data-toc-modified-id=\"Random-Forest-6.5\"><span class=\"toc-item-num\">6.5&nbsp;&nbsp;</span>Random Forest</a></span></li></ul></li><li><span><a href=\"#Clustering\" data-toc-modified-id=\"Clustering-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Clustering</a></span><ul class=\"toc-item\"><li><span><a href=\"#KMeans\" data-toc-modified-id=\"KMeans-7.1\"><span class=\"toc-item-num\">7.1&nbsp;&nbsp;</span>KMeans</a></span></li><li><span><a href=\"#Hierarchical\" data-toc-modified-id=\"Hierarchical-7.2\"><span class=\"toc-item-num\">7.2&nbsp;&nbsp;</span>Hierarchical</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96e6894",
   "metadata": {},
   "source": [
    "# VTI Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74820191",
   "metadata": {},
   "source": [
    "Vanguard Total Stock Market Exchange Traded Fund or VTI.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b5c852",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e9ebd9",
   "metadata": {},
   "source": [
    "## Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02aebb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas_datareader.data as web\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.legend_handler import HandlerLine2D\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "from pandas.plotting import scatter_matrix\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from statsmodels.graphics.gofplots import ProbPlot\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import scale,StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import pickle\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "# Scikit-learn package for data preprocessing.\n",
    "from sklearn import preprocessing\n",
    "from textwrap import wrap\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from scipy.cluster.vq import kmeans\n",
    "from sklearn import cluster\n",
    "from sklearn.cluster import KMeans, MiniBatchKMeans\n",
    "from scipy.spatial.distance import cdist,pdist\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import sklearn\n",
    "from matplotlib import cm\n",
    "from kneed import KneeLocator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8739805f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get(tickers, startdate, enddate):\n",
    "    def data(ticker):\n",
    "        return (web.get_data_yahoo(ticker, start=startdate, end=enddate))\n",
    "    datas = map (data, tickers)\n",
    "    return(pd.concat(datas, keys=tickers, names=['Ticker', 'Date']))\n",
    "\n",
    "tickers = ['VTI', 'VWO', 'VOO', 'BND']\n",
    "all_data = get(tickers, datetime.datetime(2010, 7, 21), datetime.datetime(2022, 7, 10))\n",
    "all_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1af7170",
   "metadata": {},
   "source": [
    "## Inspect Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57e5c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428404f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32265f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.info() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ff2fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf589028",
   "metadata": {},
   "source": [
    "## Changes based on Adj Close Prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6369a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data['Change in Price'] = all_data['Adj Close'].diff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a945ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f71238",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_close_px = all_data[['Adj Close']].reset_index().pivot('Date', 'Ticker', 'Adj Close').dropna()\n",
    "\n",
    "# Calculate the daily percentage change for `daily_close_px`\n",
    "daily_pct_change = daily_close_px.pct_change().dropna()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b60e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_pct_change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0790c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_close_px['BND Change'] = daily_pct_change['BND']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52eaecfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_close_px['VOO Change'] = daily_pct_change['VOO']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e08d1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_close_px['VTI Increase'] = daily_pct_change['VTI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e6398a",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_close_px['VWO Increase'] = daily_pct_change['VWO']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed111e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_close_px.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4aea13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_close_px=daily_close_px.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0af9196",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_close_px.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8899a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the distributions\n",
    "daily_close_px.hist(bins=100, sharex=True, figsize=(12,8))\n",
    "\n",
    "# Show the resulting plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3409fc31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a scatter matrix with the `daily_pct_change` data \n",
    "pd.plotting.scatter_matrix(daily_close_px, diagonal='kde', alpha=0.1,figsize=(12,12))\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "159c6c1f",
   "metadata": {},
   "source": [
    "# Simple Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "331fd81e",
   "metadata": {},
   "source": [
    "In our example, we are going to try and model the relationships between x and y. The question I am trying to answer is, does the independant variable do a good job at predicting the dependent variable.\n",
    "\n",
    "Why a linear regression model?\n",
    "\n",
    "I learned about linear regression in class and wanted to get more practice. I want to know whether one measurement variable is associated with another measurement variable. We want to measure the strength of the association (r2). I want to predict unknown values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f21b58",
   "metadata": {},
   "source": [
    "## Explore the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea2f3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10, 6))\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "plt.xlabel(\"VWO Close Price\")\n",
    "plt.ylabel(\"VTI Close Price\")\n",
    "plt.title(\"Scatter plot of Close Price\")\n",
    "plt.scatter(daily_close_px['VWO'], daily_close_px['VTI'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb725bb3",
   "metadata": {},
   "source": [
    "### Create a Statistical Summary\n",
    "Okay, so we see there is a correlation let us create a statistical summary to help describe the dataset. We will use the describe() method to output a DataFrame with all this info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499b368f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Summary statistics: dependent and independent variables \n",
    "\n",
    "# Describe the summary statistics.\n",
    "print(daily_close_px.describe())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3745d3df",
   "metadata": {},
   "source": [
    "### Measure thecorrelation\n",
    "Measure the Correlation\n",
    "\n",
    "At first glance, we can tell there is some relationship here because they seem to be moving in tandem. The relationship means if one goes up the other appears to go up as well and also tells us it appears to be a positive relationship because they both move up. However, if we would like to attach a number to this relationship so we can quantify it. Well, in this case, let us measure the correlation between the two variables. We will take the DataFrame and call the corr() method to return a DataFrame with the metrics.\n",
    "\n",
    "\n",
    "Correlation Guideline\n",
    "Very strong relationship (|r|>0.8 =>)\n",
    "Strong relationship (0.6≤|r|)\n",
    "Moderate relationship (0.4≤|r|)\n",
    "Weak relationship (0.2≤|r|)\n",
    "Very weak relationship (|r|)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b366afe8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Summary statistics: covariance in Python \n",
    "\n",
    "print(daily_close_px.cov())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc275a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Summary statistics: correlation (scaled cov) \n",
    "\n",
    "daily_close_px.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf33a51",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Data cleaning: NAs  \n",
    "\n",
    "# Check how many values are null in the column.\n",
    "print(daily_close_px.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61457571",
   "metadata": {},
   "source": [
    "\n",
    "### Checking for Outliers and Skewness\n",
    "\n",
    "We do not want outliers, and we want to make sure our data does not have skew because this could impact results in specific models. The first thing we will do is a plot a histogram for each column of data. The data will help us get a good idea of the distribution. Once, we have done that we will do some hard measurements to validate our visuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7e5f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_close_px.hist(grid = False, color = 'cadetblue')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897c0728",
   "metadata": {},
   "source": [
    "### testing for near zero variance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed09904",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_close_px_var = daily_close_px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42179f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data cleaning: testing for near zero variance  ####\n",
    "\n",
    "# Using sklearn, look for low variance within the columns.\n",
    "# selector = VarianceThreshold()\n",
    "selector = VarianceThreshold()\n",
    "# Next, name the cleaned dataset df_clean.\n",
    "df_variance_check = selector.fit_transform(daily_close_px_var)\n",
    "\n",
    "# Let's see if the dimensions changed.\n",
    "print(df_variance_check.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d26c4cd7",
   "metadata": {},
   "source": [
    "**======================================================================**\n",
    "\n",
    "Still have the same number of columns and rows. No near zero variance. \n",
    "\n",
    "**======================================================================**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2783f5fb",
   "metadata": {},
   "source": [
    "### OLS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b3f6c9",
   "metadata": {},
   "source": [
    "#### Split the Data\n",
    "The first thing we need to do is split the data into a training set and a test set. The training set is what we will train the model on and the test set is what we will test it on. The convention is to have 20% dedicated to testing and the remaining 80% to training, but these are not hard limits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c435b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modeling with our dataset  \n",
    "\n",
    "# Set X to ['Open', 'High', 'Low', 'Volume', 'Close', 'Adj Close', 'Returns'].  \n",
    "X = daily_close_px[['VWO']]\n",
    "# Add a constant.\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Set y to `Close`.\n",
    "y = daily_close_px[[\"VTI\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b745803",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the random seed equal to 1.\n",
    "np.random.seed(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47c49b1",
   "metadata": {},
   "source": [
    "#### Explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61830d99",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Building a linear model\n",
    "\n",
    "# Build the model, note the difference in argument order.\n",
    "model = sm.OLS(y, X).fit()\n",
    "# Inspect the output of the `sm.OLS` function.\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "382add6c",
   "metadata": {},
   "source": [
    "**Our Independent variable's coefficient is not zero so we reject the null hypothesis (coefficient is 0) for the T test since P value is small** \n",
    "\n",
    "**The model has predictive power (p-value for F test), however, it is close to 0.0** \n",
    "\n",
    "**We can explain about 74.7% of the variance explained**\n",
    "\n",
    "**The P(JB) is small and tells us that the residuals are not normally distributed**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13c770d",
   "metadata": {},
   "source": [
    "**========================================================================================================================**\n",
    "\n",
    "**R-Squared:** Measures how much of the independent variable (y) is explined by changes in our dependent variables (x). (how much variance is explained)\n",
    "\n",
    "**In this OLS summary only 12.3% of Cumulative Returns is explined by the changes in Volume.**\n",
    "\n",
    "**Omnibus** Describes the normalcy of the distribution of our residuals using skew and Kurtosis as measurements. A 0 would indicate perfect normalcy.\n",
    "\n",
    "**Prob(Omnibus)** A statistical test measuring the probability the residuals are normally distributed. A 1 would indicate perfectly normal distribution. \n",
    "\n",
    "**Skew** Measurement of symmertry in our data, with 0 being perfectly symmetry.\n",
    "\n",
    "**Kurtosis** measures the peakiness of our data, or its concentration around 0 in a normal curve. Higher kurtosis implies fewer outliers.\n",
    "\n",
    "**Durbin-Watson** is a measurement of homoscedasticity, or an even distribution of errors throughout our data. Ideal homoscedasticity lies between 1 and 2.\n",
    "\n",
    "**Jarque-Bera(JB)** Alternative ways of measure Omnibus.\n",
    "\n",
    "**Condition Number** measurement of the sensitivity of our model as compared to the size of changes in the dats it is analyzing. Multicollinearity describes two or more independent variables that are strongly related to each other and are fasely affecting our predicted variable by redundancy.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**========================================================================================================================**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994d3608",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = sm.graphics.abline_plot(model_results = model, color='red')\n",
    "ax = fig.axes[0]\n",
    "plt.scatter(daily_close_px['VWO'], daily_close_px['VTI'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526deb93",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.sqrt(model.scale))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef6c46f",
   "metadata": {},
   "source": [
    "## Assumptions of the Model\n",
    "\n",
    "It's essential to understand the assumptions of the model before we start building and coding. Each assumption if violated means we may have to take extra steps to improve our model or in some cases dump the model altogether. Here is a list of the assumptions of the model:\n",
    "\n",
    "A linear relationship is assumed between the dependent variable and the independent variables.\n",
    "\n",
    "Independent Residuals\n",
    "\n",
    "Regression residuals must be normally distributed.\n",
    "\n",
    "Equal Variance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c2ed2dc",
   "metadata": {},
   "source": [
    "### 1st Assumption: Linear Relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6451d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the residuals  \n",
    "\n",
    "fitted = model.fittedvalues\n",
    "print(fitted.head())\n",
    "residuals = model.resid\n",
    "print(residuals.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01673da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check for linearity.  The residuals are be scattered evenly around the dashed line at 0.\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "plot_lm_1 = plt.figure(1)\n",
    "plot_lm_1.set_figheight(8)\n",
    "plot_lm_1.set_figwidth(12)\n",
    "\n",
    "plot_lm_1.axes[0] = sns.residplot(fitted, 'VTI', \n",
    "                    data=daily_close_px, \n",
    "                    lowess = True, \n",
    "                    scatter_kws = {'alpha': 0.5}, \n",
    "                    line_kws = {'color': 'red', 'lw': 1, 'alpha': 0.8})\n",
    "\n",
    "plot_lm_1.axes[0].set_title('Residuals vs Fitted')\n",
    "plot_lm_1.axes[0].set_xlabel('Fitted values')\n",
    "plot_lm_1.axes[0].set_ylabel('Residuals')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f483c3",
   "metadata": {},
   "source": [
    "**========================================================================================================================**\n",
    "\n",
    "**Dots are clumped together,but Red line is close to 0**\n",
    "**Violates Assumption**\n",
    "\n",
    "**========================================================================================================================**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c427757c",
   "metadata": {},
   "source": [
    "### Assumption 2: Independent Residuals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2037b68",
   "metadata": {},
   "source": [
    "### Assumption 3: Normal Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7aa602",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check for normal distribution \n",
    "\n",
    "from statsmodels.graphics.gofplots import ProbPlot\n",
    "\n",
    "model_norm_residuals = model.get_influence().resid_studentized_internal\n",
    "QQ = ProbPlot(model_norm_residuals)\n",
    "plot_lm_2 = QQ.qqplot(line= '45', alpha = 0.5, color = '#4C72B0', lw = 1)\n",
    "\n",
    "plot_lm_2.set_figheight(8)\n",
    "plot_lm_2.set_figwidth(12)\n",
    "\n",
    "plot_lm_2.axes[0].set_title('Normal Q-Q')\n",
    "plot_lm_2.axes[0].set_xlabel('Theoretical Quantiles')\n",
    "plot_lm_2.axes[0].set_ylabel('Standardized Residuals')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787b7333",
   "metadata": {},
   "source": [
    "========================================================================================================================\n",
    "\n",
    "**A high JN Value and a P value of close to 0 indicates that errors are not normally distributed.**\n",
    "**Reject Null**\n",
    "\n",
    "========================================================================================================================"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd6d623",
   "metadata": {},
   "source": [
    "### Assumption 4: Equal Variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693dc256",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check for equal variance \n",
    "\n",
    "model_norm_residuals_abs_sqrt = np.sqrt(np.abs(model_norm_residuals))\n",
    "plot_lm_3 = plt.figure(3)\n",
    "plot_lm_3.set_figheight(8)\n",
    "plot_lm_3.set_figwidth(12)\n",
    "\n",
    "plt.scatter(fitted, model_norm_residuals_abs_sqrt, alpha = 0.5)\n",
    "sns.regplot(fitted, model_norm_residuals_abs_sqrt,\n",
    "            scatter = False, \n",
    "            ci = False, \n",
    "            lowess = True,\n",
    "            line_kws = {'color': 'red', 'lw': 1, 'alpha': 0.8})\n",
    "\n",
    "plot_lm_3.axes[0].set_title('Scale-Location')\n",
    "plot_lm_3.axes[0].set_xlabel('Fitted values')\n",
    "plot_lm_3.axes[0].set_ylabel('sqrt(|Standardized Residuals|)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08f9e4e",
   "metadata": {},
   "source": [
    "======================================================================================\n",
    "\n",
    "**The redline is pretty flat, however the dots are not evely scattered. This assumption is violated**\n",
    "\n",
    "======================================================================================"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de519f0",
   "metadata": {},
   "source": [
    "## Assumptions Violated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "349f0d0d",
   "metadata": {},
   "source": [
    "**Can't really use the linear model because of the assumption violations**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78dece14",
   "metadata": {},
   "source": [
    "# Multiple Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641f436d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Summary statistics: describe the dataset \n",
    "\n",
    "# Look at the summary statistics.\n",
    "print(daily_close_px.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b775547b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Summary statistics: covariance \n",
    "\n",
    "print(daily_close_px.cov())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1649d7b1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Summary statistics: correlation  \n",
    "\n",
    "print(daily_close_px.corr())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe0e43b",
   "metadata": {},
   "source": [
    "## OLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246c4469",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modeling with our dataset  \n",
    "\n",
    "# Set X to ['Open', 'High', 'Low', 'Volume', 'Close', 'Adj Close', 'Returns'].  \n",
    "X = daily_close_px[['BND', 'VWO']]\n",
    "# Add a constant.\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Set y to `Close`.\n",
    "y = daily_close_px[[\"VTI\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54269e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply regression to the dataset \n",
    "\n",
    "# Set the seed.\n",
    "np.random.seed(1)\n",
    "\n",
    "# Create the train and test sets.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)\n",
    "\n",
    "# Check to see if the datasets split correctly.\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d972d8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Multiple linear regression on a dataset\n",
    "\n",
    "# Build a linear model on training data.\n",
    "model_m = sm.OLS(y_train, X_train).fit()\n",
    "\n",
    "# Inspect the output of the `sm.OLS` function.\n",
    "print(model_m.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39f08aa",
   "metadata": {},
   "source": [
    " ### 1st Assumption: Linear Relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86b30a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assumptions\n",
    "\n",
    "fitted_m = model_m.fittedvalues\n",
    "print(fitted_m.head())\n",
    "residuals_m = model_m.resid\n",
    "print(residuals_m.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3205f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assumptions\n",
    "\n",
    "# Get the normalized residuals.\n",
    "model_m_norm_residuals = model_m.get_influence().resid_studentized_internal\n",
    "# Get the absolute squared normalized residuals.\n",
    "model_m_norm_residuals_abs_sqrt = np.sqrt(np.abs(model_m_norm_residuals))\n",
    "# Get the absolute residuals. \n",
    "model_m_abs_resid = np.abs(residuals_m)\n",
    "# Combine X_train and y_train into one dataframe for plotting.\n",
    "frames = [X_train,y_train]\n",
    "training = pd.concat(frames, axis = 1) # axis = 1 allows us to combine by columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cdc89c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assumption: residuals vs. fitted   \n",
    "# Let's look at assumption 1.\n",
    "plot_lm_1 = plt.figure(1)\n",
    "plot_lm_1.set_figheight(8)\n",
    "plot_lm_1.set_figwidth(12)\n",
    "plot_lm_1.axes[0] = sns.residplot(fitted_m, \"VTI\", data = training, \n",
    "                          lowess = True, \n",
    "                          scatter_kws = {'alpha': 0.5}, \n",
    "                          line_kws = {'color': 'red', 'lw': 1, 'alpha': 0.8})\n",
    "plot_lm_1.axes[0].set_title('Residuals vs Fitted')\n",
    "plot_lm_1.axes[0].set_xlabel('Fitted values')\n",
    "plot_lm_1.axes[0].set_ylabel('Residuals')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d92189",
   "metadata": {},
   "source": [
    "**========================================================================================================================**\n",
    "\n",
    "**Dots are clumped together. Red line is away from 0 Violates Assumption**\n",
    "\n",
    "**========================================================================================================================**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65782abf",
   "metadata": {},
   "source": [
    "### Assumption 3: Normal Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d506c6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#normally distributed residuals \n",
    "\n",
    "\n",
    "QQ = ProbPlot(model_m_norm_residuals)\n",
    "plot_lm_2 = QQ.qqplot(line = '45', alpha = 0.5, color = '#4C72B0', lw = 1)\n",
    "\n",
    "plot_lm_2.set_figheight(8)\n",
    "plot_lm_2.set_figwidth(12)\n",
    "\n",
    "plot_lm_2.axes[0].set_title('Normal Q-Q')\n",
    "plot_lm_2.axes[0].set_xlabel('Theoretical Quantiles')\n",
    "plot_lm_2.axes[0].set_ylabel('Standardized Residuals');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d6216f3",
   "metadata": {},
   "source": [
    "**========================================================================================================================**\n",
    "\n",
    "**JHigh JB value and a P value of close to 0 indicates that errors are not normally distributed. Reject Null**\n",
    "\n",
    "**High JB and Low P Value = Not Normally Distributed**\n",
    "\n",
    "**========================================================================================================================**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252da4f4",
   "metadata": {},
   "source": [
    "### Assumption 4: Equal Variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322e3907",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assumption: equal residual variance \n",
    "\n",
    "plot_lm_3 = plt.figure(3)\n",
    "plot_lm_3.set_figheight(8)\n",
    "plot_lm_3.set_figwidth(12)\n",
    "\n",
    "plt.scatter(fitted_m, model_m_norm_residuals_abs_sqrt, alpha = 0.5)\n",
    "sns.regplot(fitted_m, model_m_norm_residuals_abs_sqrt, \n",
    "            scatter = False, \n",
    "            ci = False, \n",
    "            lowess = True,\n",
    "            line_kws = {'color': 'red', 'lw': 1, 'alpha': 0.8})\n",
    "\n",
    "plot_lm_3.axes[0].set_title('Scale-Location')\n",
    "plot_lm_3.axes[0].set_xlabel('Fitted values')\n",
    "plot_lm_3.axes[0].set_ylabel('$\\sqrt{|Standardized Residuals|}$')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796a7482",
   "metadata": {},
   "source": [
    "**========================================================================================================================**\n",
    "\n",
    "**The redline is pretty flat, however the dots are not evely scattered. This assumption is violated**\n",
    "\n",
    "**========================================================================================================================**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be55b759",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Influential cases: residuals vs. leverage \n",
    "# Identify the influential points ('\\n' syntax creates a new line in the output).\n",
    "test_m = model_m.outlier_test()\n",
    "print(\"Bad data points (bonf(p) < 0.05):\\n\", test_m[test_m['bonf(p)'] < 0.05])\n",
    "# Save the final outliers.\n",
    "test_final_m = test_m[test_m['bonf(p)'] < 0.05]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba10f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing outliers from regression dataset \n",
    "\n",
    "test_final_m = test_m[test_m['bonf(p)'] < 0.05]\n",
    "# Make sure that you drop outliers from both X and y train sets.\n",
    "X_train_no_outliers = X_train.drop(test_final_m.index)\n",
    "y_train_no_outliers = y_train.drop(test_final_m.index)\n",
    "# Look at the shape of the new DataFrame to check that the rows have actually been dropped.\n",
    "print(X_train_no_outliers.shape)\n",
    "print(y_train_no_outliers.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97cb6727",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rerun multiple regression model  \n",
    "\n",
    "# Build a linear model on training data.\n",
    "model_m_no_outliers = sm.OLS(y_train_no_outliers, X_train_no_outliers).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603f1583",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the model  \n",
    "\n",
    "vif = pd.DataFrame()\n",
    "vif[\"VIF Factor\"] = [variance_inflation_factor(X_train_no_outliers.values, i) for i in range(X_train_no_outliers.shape[1])]\n",
    "vif[\"features\"] = X_train_no_outliers.columns\n",
    "print(vif)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744ea006",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing the model\n",
    "\n",
    "if vif[vif['VIF Factor'] > 10].features.shape[0] > 0:\n",
    "    print(\"Multicollinearity exists in our model\")\n",
    "else:\n",
    "    print(\"No multicollinearity exists in our model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb362510",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict values using the test data.\n",
    "prediction = model_m_no_outliers.predict(X_test)\n",
    "print(prediction.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f113d3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict: residuals of model  \n",
    "\n",
    "actual = y_test[\"VTI\"]\n",
    "prediction = model_m_no_outliers.predict(X_test)\n",
    "residuals = y_test[\"VTI\"] - prediction\n",
    "\n",
    "\n",
    "results =  pd.concat([actual.rename('actual'),\n",
    "                              prediction.rename('predicted'),\n",
    "                              residuals.rename('residuals')], axis = 1)\n",
    "print(results.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e08767",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict: mean squared error \n",
    "\n",
    "def rmse(predictions,actual):\n",
    "    return np.sqrt(((prediction-actual) ** 2).mean())\n",
    "\n",
    "print(rmse(prediction,actual))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce21b2a",
   "metadata": {},
   "source": [
    "# Nonlinear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1921666f",
   "metadata": {},
   "source": [
    "## Log-log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447edebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transforming predictor and target to log \n",
    "\n",
    "daily_close_px['VTI_log'] = np.log(daily_close_px['VTI']).dropna()\n",
    "daily_close_px['VWO_log'] = np.log(daily_close_px['VWO']).dropna()\n",
    "daily_close_px.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9c5622",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fitting the log-log model \n",
    "\n",
    "daily_close_px = sm.add_constant(daily_close_px)\n",
    "model_log = sm.OLS(daily_close_px['VTI_log'], daily_close_px.loc[:,['const','VWO']]).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99aa6cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting with the log-log model  \n",
    "\n",
    "prediction_log = model_log.predict(daily_close_px.loc[:,['const','VWO_log']])\n",
    "prediction_log[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2284d7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exponentiating the predictions \n",
    "\n",
    "prediction = np.exp(prediction_log)\n",
    "prediction[1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49efc6ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Evaluating the log-log model: chart \n",
    "\n",
    "plt.scatter(daily_close_px['VWO'],daily_close_px['VTI'])\n",
    "plt.plot(daily_close_px['VWO'], prediction, 'red')\n",
    "plt.title(\"Adj Close Price of VTI vs VWO\")\n",
    "plt.xlabel(\"VWO\")\n",
    "plt.ylabel(\"VTI\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a9e9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Slide 30: Evaluating the log-log model: RMSE  ####\n",
    "\n",
    "actual = daily_close_px['VTI']\n",
    "prediction = prediction\n",
    "residuals = actual - prediction\n",
    "loglog_results =  pd.concat([actual.rename('actual'),\n",
    "                              prediction.rename('predicted'),\n",
    "                              residuals.rename('residuals')], axis = 1)\n",
    "def rmse(predictions,actual):\n",
    "    return np.sqrt(((prediction-actual) ** 2).mean())\n",
    "    \n",
    "print(rmse(loglog_results['predicted'],loglog_results['actual']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0ca3ca",
   "metadata": {},
   "source": [
    "## Log-Lin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03903538",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the log-lin model  \n",
    "daily_close_px = sm.add_constant(daily_close_px)\n",
    "model_lin = sm.OLS(daily_close_px['VTI_log'], daily_close_px.loc[:,['const','VWO']]).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd6922f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting with the log-lin model  \n",
    "\n",
    "prediction_lin = model_lin.predict(daily_close_px.loc[:,['const','VWO']])\n",
    "prediction_lin[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97740c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exponentiating the predictions  \n",
    "\n",
    "prediction = np.exp(prediction_lin)\n",
    "prediction[1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0121e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluating the log-lin model: chart \n",
    "\n",
    "plt.scatter(daily_close_px['VWO'],daily_close_px['VTI'])\n",
    "plt.plot(daily_close_px['VWO'], prediction, 'red')\n",
    "plt.title(\"VTI VS VWO\")\n",
    "plt.xlabel(\"VWO\")\n",
    "plt.ylabel(\"VTI\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc7c05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluating the log-lin model: RMSE \n",
    "\n",
    "actual = daily_close_px['VWO']\n",
    "prediction = prediction\n",
    "residuals = actual - prediction\n",
    "loglin_results =  pd.concat([actual.rename('actual'),\n",
    "                              prediction.rename('predicted'),\n",
    "                              residuals.rename('residuals')], axis = 1)\n",
    "def rmse(predictions,actual):\n",
    "    return np.sqrt(((prediction-actual) ** 2).mean())\n",
    "    \n",
    "print(rmse(loglin_results['predicted'],loglin_results['actual']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cea87fd",
   "metadata": {},
   "source": [
    "## Polynomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cba1bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_close_px['VWOX2'] = np.power(daily_close_px['VWO'], 2)\n",
    "daily_close_px['VWOX3'] = np.power(daily_close_px['VWO'], 3)\n",
    "daily_close_px.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1a766b",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_close_px = sm.add_constant(daily_close_px)\n",
    "model_poly = sm.OLS(daily_close_px['VTI'], daily_close_px.loc[:,['const','VWO','VWOX2','VWOX3']]).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587b8e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_poly = model_poly.predict(daily_close_px.loc[:,['const','VWO', 'VWOX2', 'VWOX3']])\n",
    "prediction_poly[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd8ac7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(daily_close_px['VWO'],daily_close_px['VTI'])\n",
    "plt.plot(daily_close_px['VWO'], prediction_poly, 'red')\n",
    "plt.title(\"Cumulative Return Vs Volume\")\n",
    "plt.xlabel(\"Cumulative Return\")\n",
    "plt.ylabel(\"Volume\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4047363b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluating the polynomial model: RMSE \n",
    "\n",
    "actual = daily_close_px['VTI']\n",
    "prediction = prediction_poly\n",
    "residuals = actual - prediction\n",
    "poly_results =  pd.concat([actual.rename('actual'),\n",
    "                              prediction.rename('predicted'),\n",
    "                              residuals.rename('residuals')], axis = 1)\n",
    "def rmse(predictions,actual):\n",
    "    return np.sqrt(((prediction-actual) ** 2).mean())\n",
    "    \n",
    "print(rmse(poly_results['predicted'],poly_results['actual']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae286e82",
   "metadata": {},
   "source": [
    "# Classification "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62936b37",
   "metadata": {},
   "source": [
    "## Data Prep for Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0ea8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shows percentage change from the previous day\n",
    "daily_close_px['VTI Increase'].head(10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0c7773",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target not binary - calculate the mean and assign the above mean to 1 and below to 0\n",
    "threshold = np.mean(daily_close_px['VTI Increase'])\n",
    "daily_close_px['VTI Increase'] = np.where(daily_close_px['VTI Increase'] > threshold, 0,1)\n",
    "print(daily_close_px['VTI Increase'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d29a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inspect the dataframe. \n",
    "daily_close_px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fbe0a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for data imbalance \n",
    "print(daily_close_px['VTI Increase'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e532ddf",
   "metadata": {},
   "source": [
    "### Identify the the unique classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8040d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the the unique classes. In this case, it is going to be the percentage increase/decrease for VTI.\n",
    "unique_values = sorted(daily_close_px['VTI Increase'].unique())\n",
    "daily_close_px['VTI Increase'] = np.where(daily_close_px['VTI Increase'] == unique_values[0], False,True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f66b918",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the columns that is not going to be used\n",
    "# Split the data into X and y \n",
    "columns_to_drop_from_X = ['VTI Increase', 'VTI_log', 'VWO_log', 'VWOX2', 'VWOX3', 'const']\n",
    "X = daily_close_px.drop(columns_to_drop_from_X, axis = 1)\n",
    "y = np.array(daily_close_px['VTI Increase'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d3fd3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inspect the first five rows\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47590832",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Check the dtypes. Good to check distance\n",
    "print(X.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e2ae69",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d06702",
   "metadata": {},
   "source": [
    "### Scale "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db92d5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the seed. 70/30 to advoid overfitting and make model generalizable\n",
    "np.random.seed(1)\n",
    "\n",
    "# Split into train and test.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y, \n",
    "                                                    test_size = 0.3) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb51dc43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale X. (Distances are sensitive to large values) mean/standard deviation. \n",
    "# KNN makes a map from train to test. scale needs to be the same. \n",
    "# Scale X.\n",
    "X_train = scale(X_train)\n",
    "X_test = scale(X_test)\n",
    "print(X_train[0:4])\n",
    "print(X_test[0:4]) #comes out as an ndarray"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50eb904f",
   "metadata": {},
   "source": [
    "### Create kNN classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8a2be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create kNN classifier.\n",
    "default = 5\n",
    "kNN = KNeighborsClassifier(n_neighbors = default)\n",
    "# Fit the classifier to the data.\n",
    "kNN.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a796dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#kNN: predict on a test set \n",
    "\n",
    "predictions = kNN.predict(X_test)\n",
    "print(predictions[0:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93975f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#kNN: predict on test  \n",
    "\n",
    "actual_v_predicted = np.column_stack((y_test, predictions))\n",
    "print(actual_v_predicted[0:5])\n",
    "print(round(accuracy_score(y_test, predictions), 4))\n",
    "#y test is the first column, prediction is the second"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db6f750",
   "metadata": {},
   "source": [
    "### Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ae446b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion matrix in python\n",
    "\n",
    "# Confusion matrix for kNN.\n",
    "cm_kNN = confusion_matrix(y_test, predictions)\n",
    "print(cm_kNN)\n",
    "print(round(accuracy_score(y_test, predictions), \n",
    "4))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107e73c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion matrix: visualize  \n",
    "\n",
    "plt.imshow(cm_kNN, interpolation = 'nearest', cmap = plt.cm.Wistia)\n",
    "classNames = ['Negative', 'Positive']\n",
    "plt.title('Confusion Matrix - Test Data')\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "tick_marks = np.arange(len(classNames))\n",
    "plt.xticks(tick_marks, classNames, rotation = 45)\n",
    "plt.yticks(tick_marks, classNames)\n",
    "s = [['TN', 'FP'], ['FN', 'TP']]\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        plt.text(j,i, str(s[i][j]) + \" = \" + str(cm_kNN[i][j]))\n",
    "plt.show()\n",
    "\n",
    "#True Positive. This corresponds to how our model identified them correctly.\n",
    "#True Negative. True negatives together with true positives are the parts our model is doing right. \n",
    "#We would like to find models that maximize both of them\n",
    "#False positives. Represent the number of times that our model classified as an increase, but got wrong.\n",
    "#False Negative. An actual increase, but our model got wrong. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a34473",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation of kNN with k neighbors  ####\n",
    "\n",
    "# Create a dictionary with accuracy values for our kNN model with k.\n",
    "model_final_dict = {'metrics': [\"accuracy\"],\n",
    "                    'values':[round(accuracy_score(y_test, predictions), 4)],\n",
    "                    'model':['kNN_k']}\n",
    "model_final = pd.DataFrame(data = model_final_dict)\n",
    "print(model_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8501899",
   "metadata": {},
   "source": [
    "### AUC & ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640c7457",
   "metadata": {},
   "outputs": [],
   "source": [
    "# .predict calculates labels and .predict_proba calculates probabilities of labels\n",
    "# Anything above the threshold is true. Anything below is false\n",
    "\n",
    "# Store FPR, TPR, and threshold as variables.\n",
    "ex_fpr, ex_tpr, ex_threshold = metrics.roc_curve(y_test, kNN.predict_proba(X_test)[:,1])\n",
    "\n",
    "# Store the AUC.(Max area is 1)\n",
    "ex_roc_auc = metrics.auc(ex_fpr, ex_tpr)\n",
    "\n",
    "#Plot ROC (Receiver Operating Characteristic)\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(ex_fpr, ex_tpr, 'b', label = 'AUC = %0.2f' % ex_roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc600d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Store FPR, TPR, and threshold as variables.\n",
    "#ex_fpr, ex_tpr, ex_threshold = metrics.roc_curve(ex_y_test, ex_predictions)\n",
    "# Store the AUC.(Max area is 1)\n",
    "#ex_roc_auc = metrics.auc(ex_fpr, ex_tpr)\n",
    "# Plot ROC (Receiver Operating Characteristic)\n",
    "#plt.title('Receiver Operating Characteristic')\n",
    "#plt.plot(ex_fpr, ex_tpr, 'b', label = 'AUC = %0.2f' % ex_roc_auc)\n",
    "#plt.legend(loc = 'lower right')\n",
    "#plt.plot([0, 1], [0, 1],'r--')\n",
    "#plt.xlim([0, 1])\n",
    "#plt.ylim([0, 1])\n",
    "#plt.ylabel('True Positive Rate')\n",
    "#plt.xlabel('False Positive Rate')\n",
    "#plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad04457",
   "metadata": {},
   "source": [
    "ROC is a plot of the true positive rate (TPR) against the false positive rate (FPR) The plot illustrates the trade off\n",
    "between the TPR and FPR.\n",
    "\n",
    "The AUC is a performance metric used to compare classification models to measure predictive accuracy.\n",
    "\n",
    "The AUC should be above .5 to say the model is better than a random guess.\n",
    "\n",
    "Model is not great"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72fae3ab",
   "metadata": {},
   "source": [
    "### Grid Search to find optimal hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24db3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation pipeline for optimal accuracy \n",
    "\n",
    "# Create a pipeline of the scaler and Estimator\n",
    "cv_pipeline = Pipeline([('transformer',  StandardScaler()), ('estimator', kNN)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95b0b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cross-validation for optimal accuracy. Five cross validation folds\n",
    "\n",
    "# Calculate cv scores\n",
    "cv_scores = cross_val_score(cv_pipeline, X, y, cv = 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e3a8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cross-validation for optimal accuracy  \n",
    "\n",
    "# Print each cv score (accuracy) and average them.\n",
    "print(cv_scores)\n",
    "print(\"cv_scores mean:{}\".format(np.mean(cv_scores)))\n",
    "mean = np.mean(cv_scores)\n",
    "print(\"Optimal cv score is:\", round(mean, 4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d7e97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameter values that should be searched.\n",
    "k_range = list(range(1, 31))\n",
    "\n",
    "# Create a parameter grid: map the parameter names to the values that should be searched by building a Python dictionary.\n",
    "# key: parameter name\n",
    "# value: list of values that should be searched for that parameter\n",
    "# single key-value pair for param_grid\n",
    "param_grid = dict(n_neighbors = k_range)\n",
    "print(param_grid)\n",
    "\n",
    "# Instantiate the grid using our original model - kNN with k.\n",
    "grid = GridSearchCV(kNN, param_grid, cv = 10, scoring = 'accuracy')#10 cv folds, accuracy is the default\n",
    "\n",
    "#model is being fitted 300 times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b6f832",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding optimal k - GridSearchCV  \n",
    "\n",
    "# Create a pipeline of the scaler and gridsearch\n",
    "grid_search_pipeline = Pipeline([('transformer',  StandardScaler()), ('estimator', grid)])\n",
    "\n",
    "# Fit Gridsearch pipeline\n",
    "grid_search_pipeline.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec31b34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding optimal k - view results \n",
    "\n",
    "# View the complete results (list of named tuples).\n",
    "print(grid.cv_results_['mean_test_score'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f020cc38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding optimal k  \n",
    "\n",
    "# Create a list of the mean scores only by using a list comprehension to loop through grid.cv_results_.\n",
    "grid_mean_scores = [result for result in grid.cv_results_['mean_test_score']]\n",
    "print(grid_mean_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f5f295",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding optimal k - plot  \n",
    "\n",
    "# Plot the results.\n",
    "_ = plt.plot(k_range, grid_mean_scores)\n",
    "_ = plt.xlabel('Value of K for kNN')\n",
    "_ = plt.ylabel('Cross-Validated Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69f17b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define and examine the optimized model  \n",
    "\n",
    "# Single best score achieved across all params (k).\n",
    "print(grid.best_score_)\n",
    "grid_score = grid.best_score_\n",
    "\n",
    "# Dictionary containing the parameters (k) used to generate that score.\n",
    "print(grid.best_params_)\n",
    "\n",
    "# Actual model object fit with those best parameters.\n",
    "# Shows default parameters that we did not specify.\n",
    "print(grid.best_estimator_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e10071",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optimal model and final thoughts  \n",
    "kNN_best = grid.best_estimator_\n",
    "\n",
    "# Check accuracy of our model on the test data.\n",
    "print(kNN_best.score(X_test, y_test))\n",
    "kNN_champ = kNN_best.score(X_test, y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a8605e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Final Model   \n",
    "\n",
    "# Save this final model\n",
    "model_final = {'metrics' : \"accuracy\" , \n",
    "                                  'values' : round(kNN_champ, 4),\n",
    "                                  'model':'kNN_optimized' }\n",
    "print(model_final)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b1ccbe",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68756de6",
   "metadata": {},
   "source": [
    "**Notes**\n",
    "\n",
    "Binary\n",
    "\n",
    "Probability that y=1\n",
    "\n",
    "linear regression is slope intercept, logistic regression is a sigmoid\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68be46d4",
   "metadata": {},
   "source": [
    "### Convert Target to Binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80ce6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert target to binary\n",
    "ex_threshold = np.mean(daily_close_px['VTI Increase'])\n",
    "daily_close_px['VTI Increase'] = np.where(daily_close_px['VTI Increase'] > ex_threshold, 0,1)\n",
    "print(daily_close_px['VTI Increase'])\n",
    "\n",
    "\n",
    "# Target is binary\n",
    "print(daily_close_px['VTI Increase'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f9cbdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the two unique classes.\n",
    "ex_unique_values = sorted(daily_close_px['VTI Increase'].unique())\n",
    "daily_close_px['VTI Increase'] = np.where(daily_close_px['VTI Increase'] == ex_unique_values[0],  False,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a650e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check class again\n",
    "print(daily_close_px['VTI Increase'].dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15fd6da",
   "metadata": {},
   "source": [
    "### Check for NAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1fe67be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for NAs. \n",
    "print(daily_close_px.isnull().sum())\n",
    "\n",
    "# Delete columns containing either 60% or more than 60% NaN Values.\n",
    "#ex_perc = 60.0\n",
    "#ex_min_count =  int(((100-ex_perc)/100)*daily_close_px.shape[0] + 1)\n",
    "#daily_close_px = daily_close_px.dropna(axis=1, \n",
    "               #thresh=ex_min_count)\n",
    "print(daily_close_px.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3036505",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data prep: fillna\n",
    "\n",
    "# Function to impute NA in both numeric and categorical columns\n",
    "#def fillna(df):\n",
    "    # Fill numeric columns with mean value\n",
    "    #df = df.fillna(df.mean())    \n",
    "    # Fill categorical columns with mode value\n",
    "    #df = df.fillna(df.mode().iloc[0])\n",
    "    #return df\n",
    "  \n",
    "##df_subset = fillna(df_subset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0965d89",
   "metadata": {},
   "source": [
    "### Split data into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91bdf960",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into X and y \n",
    "ex_columns_to_drop_from_X = ['VTI Increase', 'VTI_log', 'VWO_log', 'VWOX2', 'VWOX3'] \n",
    "ex_X = daily_close_px.drop(columns_to_drop_from_X, axis=1)\n",
    "ex_y = np.array(daily_close_px['VTI Increase'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854b4e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ex_X.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e314d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split into train and test set  ####\n",
    "\n",
    "# Set the seed.\n",
    "np.random.seed(1)\n",
    "\n",
    "# Split data into train and test sets, use a 70 train - 30 test split.\n",
    "ex_X_train, ex_X_test, ex_y_train, ex_y_test = train_test_split(X, \n",
    "                                                    y, \n",
    "                                                    test_size = .3)\n",
    "                                                    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f11612",
   "metadata": {},
   "source": [
    "### Scale the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f9c300",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scale the features.  We can use the coefficient of each of the variable as a measure of importance.\n",
    "\n",
    "# Initialize scaler.\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "# Fit on training data.\n",
    "scaler.fit(X_train)\n",
    "\n",
    "# Scale training and test data.\n",
    "X_train_scaled = scaler.transform(X_train)#changes into ndarray\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a869f087",
   "metadata": {},
   "source": [
    "### Logistic regression: build "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b63cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic regression: build \n",
    "\n",
    "# Set up logistic regression model.\n",
    "logistic_regression_model = linear_model.LogisticRegression()\n",
    "print(logistic_regression_model)\n",
    "#help(logistic_regression_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa13ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic regression: fit \n",
    "\n",
    "# Fit the model.\n",
    "logistic_regression_model.fit(X_train_scaled, \n",
    "                              y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7bf955e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic regression: predict \n",
    "\n",
    "# Predict on test data.\n",
    "predicted_values = logistic_regression_model.predict(X_test_scaled)\n",
    "print(predicted_values[:20])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c271a91d",
   "metadata": {},
   "source": [
    "### Confusion matrix and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091be6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a look at test data confusion matrix.\n",
    "conf_matrix_test = metrics.confusion_matrix(y_test, predicted_values)\n",
    "print(conf_matrix_test)\n",
    "\n",
    "# Compute test model accuracy score.\n",
    "test_accuracy_score = metrics.accuracy_score(y_test, predicted_values)\n",
    "print(\"Accuracy on test data: \", test_accuracy_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490670f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification report  \n",
    "# Create a list of ex_target names to interpret class assignments.\n",
    "target_names = daily_close_px['VTI Increase'].unique()\n",
    "target_names = target_names.tolist()\n",
    "target_names = [str(x) for x in target_names]\n",
    "\n",
    "# Print an entire classification report.\n",
    "class_report = metrics.classification_report(y_test, \n",
    "                                             predicted_values, \n",
    "                                             target_names = target_names)\n",
    "print(class_report)\n",
    "\n",
    "#Accuracy, describing the number of correct predictions over all predictions\n",
    "#Precision is a measure of how many of the positive predictions made are correct\n",
    "#Recall is a measure of how many of the positive cases the classifier correctly predicted, over all the positive cases in the data\n",
    "#F1-Score (harmonic mean) is a measure combining both precision and recall. The higher, the better.\n",
    "#.predict gives us a threshold of .5\n",
    "#support is the actual number of occurrences of each class in y_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b7d5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save accuracy score  \n",
    "\n",
    "model_final = {'metrics' : \"accuracy\" , \n",
    "                'values' : round(test_accuracy_score,4),\n",
    "                'model':'logistic' }\n",
    "print(model_final)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1591a0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting probabilities instead of class labels\n",
    "\n",
    "# Get probabilities instead of predicted values.\n",
    "test_probabilities = logistic_regression_model.predict_proba(X_test_scaled)\n",
    "print(test_probabilities[0:5, :])\n",
    "# Get probabilities of test predictions only.\n",
    "test_predictions = test_probabilities[:, 1]\n",
    "print(test_predictions[0:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeec394e",
   "metadata": {},
   "source": [
    "###  Computing FPR, TPR, and threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a175050a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get FPR, TPR, and threshold values.\n",
    "fpr, tpr, threshold = metrics.roc_curve(y_test,            #<- test data labels\n",
    "                                        test_predictions)  #<- predicted probabilities\n",
    "print(\"False positive: \", fpr[:5])\n",
    "print(\"True positive: \", tpr[:5])\n",
    "print(\"Threshold: \", threshold[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce831990",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Computing AUC\n",
    "\n",
    "# Get AUC by providing the FPR and TPR.\n",
    "auc = metrics.auc(fpr, tpr)\n",
    "print(\"Area under the ROC curve: \", auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c198a678",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Putting it all together: ROC plot\n",
    "\n",
    "# Make an ROC curve plot.\n",
    "plt.title('Receiver Operator Characteristic')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1606ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scores=pd.DataFrame({'fpr':fpr, 'tpr':tpr, 'threshold':threshold})\n",
    "fig=px.scatter(df_scores, x='fpr', y='tpr', hover_data=df_scores.columns)\n",
    "fig.show()\n",
    "# threshold could have been higher than .5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a32255",
   "metadata": {},
   "source": [
    "### Accuracy on train vs. accuracy on test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9ccc2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Accuracy on train vs. accuracy on test\n",
    "\n",
    "# Compute trained model accuracy score.\n",
    "trained_accuracy_score = logistic_regression_model.score(X_train_scaled, y_train)\n",
    "print(\"Accuracy on train data: \" , trained_accuracy_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49079dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare parameters for optimization \n",
    "\n",
    "# Create regularization penalty space.\n",
    "penalty = ['l1', 'l2']\n",
    "# Create regularization constant space.\n",
    "C = np.logspace(0, 10, 10)\n",
    "print(\"Regularization constant: \", C)\n",
    "# Create hyperparameter options dictionary.\n",
    "hyperparameters = dict(C = C, penalty = penalty)\n",
    "print(hyperparameters)\n",
    "\n",
    "#20 parameter combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd223d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Solvers, liblinear (ideal for small dataset and one vs rest schemes. Penalty :L1(lasso) and L2(ridge)\n",
    "#lbfgs, default solver, ideal for large datasets and multi class problems. Penalty L2 or no penalty\n",
    "#newton-cg, ideal for large datasets and multiclass problemts. Penalty L2 or no penalty.\n",
    "#sag, works faster on large datasets and handles multiclass problems. L2 or no penlaty.\n",
    "#saga, works faster on alrge datasets and handles multiclass problems. L1,L2, elastic net or no penalty."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77c0b9e",
   "metadata": {},
   "source": [
    "### Grid Search to find optimal hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a82853",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set up cross-validation logistic function \n",
    "\n",
    "# Grid search 10-fold cross-validation with above parameters.\n",
    "clf = GridSearchCV(linear_model.LogisticRegression(solver='liblinear', max_iter = 550), #<- function to optimize\n",
    "                   hyperparameters,                   #<- grid search parameters\n",
    "                   cv = 15,                           #<- 10-fold cv\n",
    "                   verbose = 0)                       #<- no messages to show\n",
    "# Fit CV grid search.\n",
    "best_model = clf.fit(X_train_scaled, y_train)\n",
    "best_model\n",
    "#Model will run 300 times. (penalty = 2, cv=15, 10 for regularization space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03af4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check best parameters found by CV  \n",
    "\n",
    "# Get best penalty and constant parameters.\n",
    "penalty = best_model.best_estimator_.get_params()['penalty']\n",
    "constant = best_model.best_estimator_.get_params()['C']\n",
    "print('Best penalty: ', penalty)\n",
    "print('Best C: ', constant)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2570b019",
   "metadata": {},
   "source": [
    "### Predict using the best model parameters  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8f6869",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on test data using best model.\n",
    "best_predicted_values = best_model.predict(X_test_scaled)\n",
    "print(best_predicted_values)\n",
    "# Compute best model accuracy score.\n",
    "best_accuracy_score = metrics.accuracy_score(y_test, best_predicted_values)\n",
    "print(\"Accuracy on test data (best model): \", best_accuracy_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb04e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy on train vs. accuracy on test  \n",
    "\n",
    "# Compute trained model accuracy score.\n",
    "trained_accuracy_score = best_model.score(X_train_scaled, y_train)\n",
    "print(\"Accuracy on train data: \" , trained_accuracy_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6deb507e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assessing the tuned model \n",
    "\n",
    "# Compute confusion matrix for best model.\n",
    "best_confusion_matrix = metrics.confusion_matrix(y_test, best_predicted_values)\n",
    "print(best_confusion_matrix)\n",
    "# Create a list of target names to interpret class assignments.\n",
    "target_names = ['Low value', 'High value']\n",
    "# Compute classification report for best model.\n",
    "best_class_report = metrics.classification_report(y_test, best_predicted_values, \n",
    "                                                  target_names = target_names)\n",
    "print(best_class_report)\n",
    "\n",
    "#Accuracy, describing the number of correct predictions over all predictions\n",
    "#Precision is a measure of how many of the positive predictions made are correct\n",
    "#Recall is a measure of how many of the positive cases the classifier correctly predicted, over all the positive cases in the data\n",
    "#F1-Score (harmonic mean) is a measure combining both precision and recall. The higher, the better.\n",
    "#.predict gives us a threshold of .5\n",
    "#support is the actual number of occurrences of each class in y_test.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364ce54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save accuracy score  \n",
    "\n",
    "model_final = {'metrics' : \"accuracy\", \n",
    "                                  'values' : round(best_accuracy_score, 4),\n",
    "                                  'model':'logistic_tuned' }\n",
    "print(model_final)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46546d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get metrics for ROC curve  \n",
    "\n",
    "# Get probabilities instead of predicted values.\n",
    "best_test_probabilities = best_model.predict_proba(X_test_scaled)\n",
    "print(best_test_probabilities[0:5, ])\n",
    "# Get probabilities of test predictions only.\n",
    "best_test_predictions = best_test_probabilities[:, 1]\n",
    "print(best_test_predictions[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda15b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get metrics for ROC curve\n",
    "\n",
    "# Get ROC curve metrics.\n",
    "best_fpr, best_tpr, best_threshold = metrics.roc_curve(y_test, best_test_predictions)\n",
    "best_auc = metrics.auc(best_fpr, best_tpr)\n",
    "print(best_auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c486720e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ROC curve for both models \n",
    "# Make an ROC curve plot.\n",
    "plt.title('Receiver Operator Characteristic')\n",
    "plt.plot(fpr, tpr, 'blue', \n",
    "         label = 'AUC = %0.2f'%auc)\n",
    "plt.plot(best_fpr, best_tpr, 'black', \n",
    "         label = 'AUC (best) = %0.2f'%best_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe084f82",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04db508",
   "metadata": {},
   "source": [
    "Every decision tree starts with a specific decision called the root node. The root and leaf nodes hold\n",
    "questions you have to answer. Branches are lines that connect the nodes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2d57a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_small = X.iloc[0:250]\n",
    "y_small = y[0:250]\n",
    "\n",
    "# Set the seed to 1.\n",
    "np.random.seed(1)\n",
    "\n",
    "# Implement the Decision Tree on X.\n",
    "clf = tree.DecisionTreeClassifier() #created the object\n",
    "clf_fit = clf.fit(X_small, y_small)\n",
    "print(clf_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99506adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,25))\n",
    "# Visualize `clf_fit_small`\n",
    "tree.plot_tree(clf_fit, \n",
    "              feature_names= X.columns,  \n",
    "              filled=True)\n",
    "plt.show()\n",
    "\n",
    "# Split into train and test.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773235ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement the Decision Tree on X_train.\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf_fit = clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on ex_X_test.\n",
    "y_predict = clf_fit.predict(X_test)\n",
    "y_predict[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790dffe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model \n",
    "\n",
    "# Confusion matrix for first model.\n",
    "cm_tree = confusion_matrix(y_test,y_predict)\n",
    "# Accuracy score.\n",
    "acc_score = accuracy_score(y_test, y_predict)\n",
    "print(acc_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383dd9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix \n",
    "\n",
    "plt.clf()\n",
    "plt.imshow(cm_tree, interpolation='nearest', cmap=plt.cm.Wistia)\n",
    "classNames = ['Negative','Positive']\n",
    "plt.title('Confusion Matrix - Test Data')\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "tick_marks = np.arange(len(classNames))\n",
    "plt.xticks(tick_marks, classNames, rotation=45)\n",
    "plt.yticks(tick_marks, classNames)\n",
    "s = [['TN','FP'], ['FN', 'TP']]\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        plt.text(j,i, str(s[i][j]) + \" = \" + str(cm_tree[i][j]))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4c23bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot ROC and calculate AUC \n",
    "\n",
    "# Calculate metrics for ROC (fpr, tpr) and calculate AUC.\n",
    "fpr, tpr, threshold = metrics.roc_curve(y_test, y_predict)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "# Plot ROC.\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696632a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decision Tree: build\n",
    "\n",
    "# Set up logistic regression model.\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "print(clf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa1a822",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model.\n",
    "clf_fit = clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdfc4dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree: predict\n",
    "\n",
    "# Predict on X_test.\n",
    "y_predict = clf_fit.predict(X_test)\n",
    "print(y_predict[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb27924",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree: accuracy score  \n",
    "\n",
    "# Compute test model accuracy score.\n",
    "tree_accuracy_score = metrics.accuracy_score(y_test, y_predict)\n",
    "print(\"Accuracy on test data: \", tree_accuracy_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb377dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree: train accuracy  \n",
    "\n",
    "# Compute accuracy using training data.\n",
    "acc_train_tree = clf_fit.score(X_train,\n",
    "                                 y_train)\n",
    "print (\"Train Accuracy:\", acc_train_tree)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183a8e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree: accuracy  \n",
    "\n",
    "# Save this model to use later if needed\n",
    "model_final_tree = {'metrics' : \"accuracy\" , \n",
    "                                  'values' : round(tree_accuracy_score,4),\n",
    "                                  'model':'tree_all_variables' }\n",
    "print(model_final_tree)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5807a9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation scores  \n",
    "\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "cv_scores = cross_val_score(clf, X, y, cv = 10)\n",
    "# Print each cv score (accuracy) and average them.\n",
    "print(cv_scores)\n",
    "print(\"cv_scores mean:{}\".format(np.mean(cv_scores)))\n",
    "mean = np.mean(cv_scores)\n",
    "print(\"Optimal cv score is:\", round(mean, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7157cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define an optimal number function  \n",
    "\n",
    "# Define function that will determine the optimal number for each parameter.\n",
    "def optimal_parameter(values,test_results):\n",
    "    best_test_value = max(test_results)\n",
    "    best_test_index = test_results.index(best_test_value)\n",
    "    best_value = values[best_test_index]\n",
    "    return(best_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f34303c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimize: max depth  \n",
    "\n",
    "# Max depth:\n",
    "max_depths = np.linspace(1, 32, 32, endpoint = True)\n",
    "train_results = []\n",
    "test_results = []\n",
    "\n",
    "for max_depth in max_depths:\n",
    "   dt = DecisionTreeClassifier(max_depth = max_depth)\n",
    "   dt.fit(X_train, y_train)\n",
    "   \n",
    "   train_pred = dt.predict(X_train)\n",
    "   acc_train = accuracy_score(y_train, train_pred)\n",
    "   \n",
    "   # Add accuracy score to previous train results\n",
    "   train_results.append(acc_train)\n",
    "   y_pred = dt.predict(X_test)\n",
    "   acc_test = accuracy_score(y_test, y_pred)\n",
    "   # Add accuracy score to previous test results\n",
    "   test_results.append(acc_test)\n",
    "# Store optimal max_depth.\n",
    "optimal_max_depth = optimal_parameter(max_depths,test_results)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf8de73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot: max depth  \n",
    "\n",
    "# Plot max depth over 1 - 32. \n",
    "line1, = plt.plot(max_depths, train_results, 'b', label= \"Train accuracy\")\n",
    "line2, = plt.plot(max_depths, test_results, 'r', label= \"Test accuracy\")\n",
    "\n",
    "plt.legend(handler_map={line1: HandlerLine2D(numpoints = 2)})\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Tree depth')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67f548c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimize: min samples split \n",
    "\n",
    "min_samples_splits = np.linspace(0.1, 1.0, 10, endpoint=True)\n",
    "train_results = []\n",
    "test_results = []\n",
    "\n",
    "for min_samples_split in min_samples_splits:\n",
    "   dt = DecisionTreeClassifier(min_samples_split=min_samples_split)\n",
    "   dt.fit(X_train, y_train)\n",
    "   train_pred = dt.predict(X_train)\n",
    "   acc_train = accuracy_score(y_train, train_pred)\n",
    "   # Add accuracy score to previous train results\n",
    "   train_results.append(acc_train)\n",
    "   y_pred = dt.predict(X_test)\n",
    "   acc_test = accuracy_score(y_test, y_pred)\n",
    "   # Add accuracy score to previous test results\n",
    "   test_results.append(acc_test)\n",
    "# Store optimal max_depth.\n",
    "optimal_min_samples_split = optimal_parameter(min_samples_splits,test_results) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cec0082",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot: min samples split  \n",
    "\n",
    "# Plot min_sample split.\n",
    "line1, = plt.plot(min_samples_splits, train_results, 'b', label = \"Train accuracy\")\n",
    "line2, = plt.plot(min_samples_splits, test_results, 'r', label = \"Test accuracy\")\n",
    "\n",
    "plt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('min samples split')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e84f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimize: min samples leaf \n",
    "\n",
    "# Min_samples_leaf:\n",
    "min_samples_leafs = np.linspace(0.1, 0.5, 5, endpoint = True)\n",
    "train_results = []\n",
    "test_results = []\n",
    "\n",
    "for min_samples_leaf in min_samples_leafs:\n",
    "   dt = DecisionTreeClassifier(min_samples_leaf=min_samples_leaf)\n",
    "   dt.fit(X_train, y_train)\n",
    "   train_pred = dt.predict(X_train)\n",
    "   acc_train = accuracy_score(y_train, train_pred)\n",
    "   # Add accuracy score to previous train results\n",
    "   train_results.append(acc_train)\n",
    "   y_pred = dt.predict(X_test)\n",
    "   acc_test = accuracy_score(y_test, y_pred)\n",
    "   # Add accuracy score to previous test results\n",
    "   test_results.append(acc_test)\n",
    "optimal_min_samples_leafs = optimal_parameter(min_samples_leafs,test_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8ea69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot min_sample split.\n",
    "line1, = plt.plot(min_samples_leafs, train_results, 'b', label= \"Train accuracy\")\n",
    "line2, = plt.plot(min_samples_leafs, test_results, 'r', label= \"Test accuracy\")\n",
    "\n",
    "plt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('min samples leafs')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c601d1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimize: max features  \n",
    "\n",
    "# Max_features:\n",
    "max_features = list(range(1,X.shape[1]))\n",
    "train_results = []\n",
    "test_results = []\n",
    "\n",
    "for max_feature in max_features:\n",
    "   dt = DecisionTreeClassifier(max_features=max_feature)\n",
    "   dt.fit(X_train, y_train)\n",
    "   train_pred = dt.predict(X_train)\n",
    "   acc_train = accuracy_score(y_train, train_pred)\n",
    "   # Add accuracy score to previous train results\n",
    "   train_results.append(acc_train)\n",
    "   y_pred = dt.predict(X_test)\n",
    "   acc_test = accuracy_score(y_test, y_pred)\n",
    "   \n",
    "   # Add accuracy score to previous test results\n",
    "   test_results.append(acc_test)\n",
    "optimal_max_features = optimal_parameter(max_features,test_results) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03eb0ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot: max features \n",
    "\n",
    "# Plot min_sample split.\n",
    "line1, = plt.plot(max_features, train_results, 'b', label= \"Train accuracy\")\n",
    "line2, = plt.plot(max_features, test_results, 'r', label= \"Test accuracy\")\n",
    "\n",
    "plt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('max features')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27b76cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimized model \n",
    "\n",
    "print(\"The optimal max depth is:\", optimal_max_depth)\n",
    "print(\"The optimal min samples split is:\", optimal_min_samples_split)\n",
    "print(\"The optimal min samples leaf is:\", optimal_min_samples_leafs)\n",
    "print(\"The optimal max features is:\", optimal_max_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c6db2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build optimized model\n",
    "\n",
    "# Set the seed.\n",
    "np.random.seed(1)\n",
    "\n",
    "# Implement the Decision Tree on X_train.\n",
    "clf_optimized = tree.DecisionTreeClassifier(max_depth = optimal_max_depth,\n",
    "                                            min_samples_split = optimal_min_samples_split,\n",
    "                                            min_samples_leaf = optimal_min_samples_leafs,\n",
    "                                            max_features = optimal_max_features)\n",
    "                                            \n",
    "# We can now see our optimized features where before they were just default:\n",
    "print(clf_optimized)\n",
    "clf_optimized_fit = clf_optimized.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f84f0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict with optimized model  \n",
    "\n",
    "# Predict on X_test.\n",
    "y_predict_optimized = clf_optimized_fit.predict(X_test)\n",
    "\n",
    "# Get the accuracy score.\n",
    "acc_score_tree_optimized = accuracy_score(y_test, y_predict_optimized)\n",
    "\n",
    "print(acc_score_tree_optimized)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a526377",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train accuracy \n",
    "\n",
    "# Compute accuracy using training data.\n",
    "acc_train_tree_optimized = clf_optimized_fit.score(X_train,\n",
    "                                         y_train)\n",
    "                                         \n",
    "print (\"Train Accuracy:\", acc_train_tree_optimized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf4bced",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict and save results  \n",
    "\n",
    "# Add the optimized model to our dataframe.\n",
    "model_final_tree = {'metrics' : \"accuracy\" , \n",
    "             'values' : round(acc_score_tree_optimized,4),\n",
    "             'model':'tree_all_variables_optimized' }\n",
    "print(model_final_tree)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b3a836",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277357cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building a forest. Number of trees ~ 100 or number of features (sqtr of p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d81ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = daily_close_px.drop(columns_to_drop_from_X, axis = 1)\n",
    "y = np.array(daily_close_px['VTI Increase'])\n",
    "\n",
    "# Set the seed to 1.\n",
    "np.random.seed(1)\n",
    "\n",
    "# Split into the training and test sets.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f9f8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = RandomForestClassifier(criterion = 'gini', \n",
    "                                n_estimators = 100, \n",
    "                                random_state = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d0fa8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the saved model to your training data.\n",
    "forest.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed75e915",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on test data.\n",
    "y_predict_forest = forest.predict(X_test)\n",
    "\n",
    "# Look at the first few predictions.\n",
    "print(y_predict_forest[0:10,])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aefec9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a look at test data confusion matrix.\n",
    "conf_matrix_forest = metrics.confusion_matrix(y_test, y_predict_forest)\n",
    "print(conf_matrix_forest)\n",
    "accuracy_forest = metrics.accuracy_score(y_test, y_predict_forest)\n",
    "print(\"Accuracy for random forest on test data: \", accuracy_forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64a5d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute accuracy using training data.\n",
    "acc_train_forest = forest.score(X_train, y_train)\n",
    "\n",
    "print (\"Train Accuracy:\", acc_train_forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec879f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "close_features = daily_close_px.drop(columns_to_drop_from_X, axis = 1)\n",
    "features = close_features.columns\n",
    "importances = forest.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "top_indices = indices[0:10][::-1]\n",
    "\n",
    "plt.figure(1)\n",
    "plt.title('Feature Importance')\n",
    "plt.barh(range(len(top_indices)), importances[top_indices], color = 'b', align = 'center')\n",
    "labels = features[top_indices]\n",
    "labels = [ '\\n'.join(wrap(l,13)) for l in labels ]\n",
    "plt.yticks(range(len(top_indices)), labels)\n",
    "plt.xlabel('Relative Importance')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16756e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Boosting: build model  ####\n",
    "\n",
    "# Save the parameters we will be using for our gradient boosting classifier.\n",
    "gbm = GradientBoostingClassifier(n_estimators = 200, \n",
    "                                learning_rate = 1,\n",
    "                                max_depth = 2, \n",
    "                                random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0cebbf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the saved model to your training data.\n",
    "gbm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d98df7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Boosting: predict  ####\n",
    "\n",
    "# Predict on test data.\n",
    "predicted_values_gbm = gbm.predict(X_test)\n",
    "print(predicted_values_gbm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48edaa6b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Confusion matrix and accuracy  ####\n",
    "\n",
    "# Take a look at test data confusion matrix.\n",
    "conf_matrix_boosting = metrics.confusion_matrix(y_test, predicted_values_gbm)\n",
    "print(conf_matrix_boosting)\n",
    "# Compute test model accuracy score.\n",
    "accuracy_gbm = metrics.accuracy_score(y_test, predicted_values_gbm)\n",
    "print('Accuracy of gbm on test data: ', accuracy_gbm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920fa7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy of training model \n",
    "\n",
    "# Compute accuracy using training data.\n",
    "train_accuracy_gbm = gbm.score(X_train, y_train)\n",
    "print (\"Train Accuracy:\", train_accuracy_gbm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a243a641",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our top 10 features  \n",
    "\n",
    "features = close_features.columns\n",
    "importances = gbm.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "top_indices = indices[0:10][::-1]\n",
    "\n",
    "plt.figure(1)\n",
    "plt.title('Feature Importance')\n",
    "plt.barh(range(len(top_indices)), importances[top_indices], color = 'b', align = 'center')\n",
    "labels = features[top_indices]\n",
    "labels = [ '\\n'.join(wrap(l,13)) for l in labels ]\n",
    "plt.yticks(range(len(top_indices)), features[top_indices])\n",
    "plt.xlabel('Relative Importance')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c67e3b0",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8a24ba",
   "metadata": {},
   "source": [
    "## KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e611cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Subset data\n",
    "\n",
    "\n",
    "df_cluster = daily_close_px[['BND', 'VTI', 'VOO', 'VWO']]\n",
    "print(df_cluster.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3d2396",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data cleaning: NAs  \n",
    "print(df_cluster.isnull().sum())\n",
    "df_cluster = df_cluster.fillna(df_cluster.mean())\n",
    "print(df_cluster.isnull().sum())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ea80ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data type of our variables.\n",
    "print(df_cluster.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ac0eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-means data prep using  MinMaxScaler \n",
    "\n",
    "# Instantiate MinMaxScaler.\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Scale the dataframe.\n",
    "df_cluster_scaled = scaler.fit_transform(df_cluster)\n",
    "# Convert back to dataframe, making sure to name the columns again.\n",
    "df_kmeans = pd.DataFrame(df_cluster_scaled, columns = df_cluster.columns)\n",
    "print(df_kmeans.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00cfc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot matrix of numeric variables  \n",
    "# Make scatter plot.\n",
    "scatter_m = scatter_matrix(df_kmeans)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6504a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-means - start with 2 clusters.\n",
    "# Initializing K-means.\n",
    "kmeans_default = KMeans(n_clusters=2)\n",
    "# Fitting with inputs.\n",
    "kmeans_default = kmeans_default.fit(df_kmeans)\n",
    "# Predicting the clusters.\n",
    "labels = kmeans_default.predict(df_kmeans)\n",
    "# Getting the cluster centers.\n",
    "C_default = kmeans_default.cluster_centers_\n",
    "print(C_default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44adfd07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-means: plot k=2\n",
    "\n",
    "# First, we plot our clusters, colored in by the labels.\n",
    "plt.scatter(df_kmeans.iloc[:,0],\n",
    "            df_kmeans.iloc[:,1],\n",
    "            c=kmeans_default.labels_,\n",
    "            cmap='rainbow')\n",
    "# Second, we plot the optimized centroids over the clusters.\n",
    "plt.scatter(C_default[:, 0],\n",
    "            C_default[:, 1],\n",
    "            c='black',\n",
    "            s=200,\n",
    "            alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb7e273",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elbow method \n",
    "\n",
    "# Set the range of k.\n",
    "K_MAX = 10\n",
    "KK = range(1, K_MAX+1)\n",
    "\n",
    "# Run `kmeans` for values in the range k = 1-10.\n",
    "KM = [kmeans(df_kmeans,k) for k in KK]\n",
    "\n",
    "# Find the centroids for each KM output. \n",
    "centroids = [cent for (cent,var) in KM]\n",
    "\n",
    "# Calculate centroids for each iteration of k. \n",
    "D_k = [cdist(df_kmeans, cent, 'euclidean') for cent in centroids]\n",
    "cIdx = [np.argmin(D,axis=1) for D in D_k]\n",
    "dist = [np.min(D,axis=1) for D in D_k]\n",
    "\n",
    "tot_withinss = [sum(d**2) for d in dist]              # Total within-cluster sum of squares\n",
    "totss = sum(pdist(df_kmeans)**2)/df_kmeans.shape[0]   # The total sum of squares\n",
    "betweenss = totss - tot_withinss                      # The between-cluster sum of squares\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5512d847",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building our elbow plot\n",
    "\n",
    "clr = cm.Spectral( np.linspace(0,1,10) ).tolist()\n",
    "mrk = 'os^p<dvh8>+x.'\n",
    "\n",
    "# Elbow plot - explained variance.\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.plot(KK, betweenss/totss*100, 'b*-')\n",
    "ax.set_ylim((0,100))\n",
    "plt.grid(True)\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('Percentage of variance explained (%)')\n",
    "plt.title('Elbow for KMeans clustering')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9baf3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building our elbow plot \n",
    "\n",
    "# Find the knee point in the curve.\n",
    "kl = KneeLocator(x = KK, y = betweenss/totss*100,\n",
    "                 curve = 'concave', \n",
    "                 direction = 'increasing', \n",
    "                 S = 1)\n",
    "kl.plot_knee()\n",
    "elbow_cluster = kl.knee\n",
    "print(elbow_cluster)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0976c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-means: silhouette method\n",
    "obs = df_kmeans\n",
    "silhouette_score_values = list()\n",
    "NumberOfClusters = range(2, K_MAX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ebb2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-means: silhouette method \n",
    "\n",
    "for i in NumberOfClusters:\n",
    "    classifier = cluster.KMeans(i,\n",
    "                                init = 'k-means++', \n",
    "                                n_init = 10, \n",
    "                                max_iter = 300, \n",
    "                                tol = 0.0001, \n",
    "                                verbose = 0, \n",
    "                                random_state = None, \n",
    "                                copy_x = True)\n",
    "    classifier.fit(obs)\n",
    "    labels= classifier.predict(obs)\n",
    "    sklearn.metrics.silhouette_score(obs,\n",
    "                                     labels,\n",
    "                                     metric = 'euclidean', \n",
    "                                     sample_size = None, \n",
    "                                     random_state = None)\n",
    "    silhouette_score_values.append(sklearn.metrics.silhouette_score(\n",
    "                                    obs,\n",
    "                                    labels,\n",
    "                                    metric = 'euclidean', \n",
    "                                    sample_size = None,\n",
    "                                    random_state = None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676c2d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-means: silhouette method\n",
    "\n",
    "plt.plot(NumberOfClusters, silhouette_score_values)\n",
    "plt.title(\"Silhouette score values vs Numbers of Clusters \")\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a90d8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-means: silhouette method \n",
    "\n",
    "sil_cluster = NumberOfClusters[silhouette_score_values.index(max(silhouette_score_values))]\n",
    "print(\"Optimal number of components is:\", sil_cluster)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a4e107",
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-means: silhouette method \n",
    "\n",
    "optimal_clusters = min(elbow_cluster, sil_cluster)\n",
    "print(optimal_clusters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904a19bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline vs. optimal k  \n",
    "\n",
    "# Explained variance for default number of clusters.\n",
    "print(betweenss[2 - 1]/totss * 100)\n",
    "# Explained variance for optimal number of clusters.\n",
    "print(betweenss[optimal_clusters - 1]/totss * 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6380eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run optimal k  \n",
    "\n",
    "# Initializing K-means.\n",
    "kmeans_optimal = KMeans(n_clusters = optimal_clusters)\n",
    "# Fitting with inputs.\n",
    "kmeans_optimal = kmeans_optimal.fit(df_kmeans)\n",
    "# Predicting the clusters.\n",
    "labels = kmeans_optimal.predict(df_kmeans)\n",
    "# Getting the cluster centers.\n",
    "C_optimal = kmeans_optimal.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492e2f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot k = 3\n",
    "\n",
    "# First we plot our clusters, colored in by the labels.\n",
    "plt.scatter(df_kmeans.iloc[:,0],            \n",
    "            df_kmeans.iloc[:,1], \n",
    "            c = kmeans_optimal.labels_, \n",
    "            cmap = 'rainbow')\n",
    "# Second, we plot the optimized centroids over the clusters.\n",
    "plt.scatter(C_optimal[:, 0], \n",
    "            C_optimal[:, 1], \n",
    "            c = 'black', \n",
    "            s = 200, \n",
    "            alpha = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd4f1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot k = 2 vs. k = 3  \n",
    "\n",
    "plt.clf()\n",
    "plt.rcParams.update({'font.size': 20})\n",
    "plt.figure(figsize = (16, 8))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(df_kmeans.iloc[:,0],df_kmeans.iloc[:,1],c=kmeans_default.labels_,cmap='rainbow')\n",
    "plt.scatter(C_default[:, 0], C_default[:, 1], c='black', s=200,alpha=0.5)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(df_kmeans.iloc[:,0],df_kmeans.iloc[:,1],\n",
    "c=kmeans_optimal.labels_, cmap='rainbow')\n",
    "plt.scatter(C_optimal[:, 0], C_optimal[:, 1], c='black', s=200, alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1b3e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect clusters  \n",
    "\n",
    "# Append the other variables back to the dataframe with clusters.\n",
    "clustered_df = df_cluster \n",
    "# Add cluster numbers.\n",
    "clustered_df['clusters'] = pd.Series(labels)\n",
    "print(clustered_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89456d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect clusters  \n",
    "\n",
    "# Group by `clusters` column to see the group mean of each variable.\n",
    "cluster_groups_means = clustered_df.groupby('clusters').mean()\n",
    "print(cluster_groups_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068b3618",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mini-Batch K-means: with k=2  \n",
    "\n",
    "# Mini-Batch K-means - start with 2 clusters \n",
    "# and batch size of 40\n",
    "mbkm = MiniBatchKMeans(n_clusters=2, batch_size=40)\n",
    "# Fitting with inputs.\n",
    "mbkm_default = mbkm.fit(df_kmeans)\n",
    "# Predicting the clusters.\n",
    "mbkm_labels = mbkm_default.predict(df_kmeans)\n",
    "# Getting the cluster centers.\n",
    "mbkm_C_default = mbkm_default.cluster_centers_\n",
    "print(mbkm_C_default)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247f76d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mini-Batch K-means: plot k=2 \n",
    "\n",
    "# First, we plot our clusters, colored in by the labels.\n",
    "plt.scatter(df_kmeans.iloc[:,0],\n",
    "            df_kmeans.iloc[:,1],\n",
    "            c=mbkm_default.labels_,\n",
    "            cmap='rainbow')\n",
    "# Second, we plot the optimized centroids over the clusters.\n",
    "plt.scatter(mbkm_C_default[:, 0],\n",
    "            mbkm_C_default[:, 1],\n",
    "            c='black',\n",
    "            s=200,\n",
    "            alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035d0a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the results \n",
    "\n",
    "from sklearn.metrics.pairwise import pairwise_distances_argmin\n",
    "# Initiate the plot\n",
    "n_clusters = 2\n",
    "X = np.array(df_kmeans)\n",
    "fig = plt.figure(figsize=(18, 8))\n",
    "fig.subplots_adjust(left=0.02, right=0.98, bottom=0.05, top=0.9)\n",
    "colors = ['#4EACC5', '#FF9C34', '#4E9A06']\n",
    "# We want to have the same colors for the same cluster from the\n",
    "# MiniBatchKMeans and the KMeans algorithm. Let's pair the cluster centers per closest one.\n",
    "k_means_cluster_centers = kmeans_default.cluster_centers_\n",
    "order = pairwise_distances_argmin(kmeans_default.cluster_centers_, mbkm_default.cluster_centers_)\n",
    "mbk_means_cluster_centers = mbkm_default.cluster_centers_[order]\n",
    "\n",
    "k_means_labels = pairwise_distances_argmin(df_kmeans, k_means_cluster_centers)\n",
    "mbk_means_labels = pairwise_distances_argmin(df_kmeans, mbk_means_cluster_centers)\n",
    "\n",
    "# Plot KMeans\n",
    "ax = fig.add_subplot(1, 3, 1)\n",
    "for k, col in zip(range(n_clusters), colors):\n",
    "    my_members = k_means_labels == k\n",
    "    cluster_center = k_means_cluster_centers[k]\n",
    "    ax.plot(X[my_members, 0], X[my_members, 1], 'w',\n",
    "            markerfacecolor=col, marker='.',markersize=14)\n",
    "    ax.plot(cluster_center[0], cluster_center[1], 'o', markerfacecolor='k', alpha=0.5,\n",
    "            markeredgecolor='k', markersize=14)\n",
    "ax.set_title('KMeans')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6589bb0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the results \n",
    "\n",
    "# Plot MiniBatchKMeans\n",
    "ax = fig.add_subplot(1, 3, 2)\n",
    "for k, col in zip(range(n_clusters), colors):\n",
    "    my_members = mbk_means_labels == k\n",
    "    cluster_center = mbk_means_cluster_centers[k]\n",
    "    ax.plot(X[my_members, 0], X[my_members, 1], 'w',\n",
    "            markerfacecolor=col, marker='.', markersize=14)\n",
    "    ax.plot(cluster_center[0], cluster_center[1], 'o', markerfacecolor='k',alpha=0.5,\n",
    "            markeredgecolor='k', markersize=14)\n",
    "ax.set_title('MiniBatchKMeans')\n",
    "\n",
    "# Initialize the different array to all False\n",
    "different = (mbk_means_labels == 4)\n",
    "ax = fig.add_subplot(1, 3, 3)\n",
    "\n",
    "for k in range(n_clusters):\n",
    "    different += ((k_means_labels == k) != (mbk_means_labels == k))\n",
    "\n",
    "identic = np.logical_not(different)\n",
    "ax.plot(X[identic, 0], X[identic, 1], 'w',\n",
    "        markerfacecolor='#bbbbbb', marker='.',markersize=14)\n",
    "ax.plot(X[different, 0], X[different, 1], 'w',\n",
    "        markerfacecolor='m', marker='.',markersize=14)\n",
    "ax.set_title('Difference')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98580f06",
   "metadata": {},
   "source": [
    "## Hierarchical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9430a319",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_hier.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492a39a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute distance matrix\n",
    "\n",
    "# Calculate the distance matrix.\n",
    "df_dist = pdist(df_hier, 'euclidean')\n",
    "df_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5f077d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "1149px",
    "left": "21px",
    "top": "111.12px",
    "width": "502.594px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
